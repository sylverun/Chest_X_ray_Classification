{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94c8601a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv2D, LeakyReLU,Dropout,BatchNormalization,Dense,MaxPooling2D, Input, Flatten,Concatenate\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from keras.optimizers import Adamax\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f44c8686",
   "metadata": {},
   "outputs": [],
   "source": [
    "data='df_modif_auto.pkl'\n",
    "\n",
    "with open(data, 'rb') as f:\n",
    "    df_modif = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "baddf3fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "      <th>path</th>\n",
       "      <th>outputs_256_to_128_norm</th>\n",
       "      <th>erreur_256_to_128_norm</th>\n",
       "      <th>outputs_256_to_128_pneumo</th>\n",
       "      <th>erreur_256_to_128_pneumo</th>\n",
       "      <th>outputs_256_to_128_covid</th>\n",
       "      <th>erreur_256_to_128_covid</th>\n",
       "      <th>outputs_128_to_256_norm</th>\n",
       "      <th>erreur_128_to_256_norm</th>\n",
       "      <th>outputs_128_to_256_pneumo</th>\n",
       "      <th>erreur_128_to_256_pneumo</th>\n",
       "      <th>outputs_128_to_256_covid</th>\n",
       "      <th>erreur_128_to_256_covid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7005867.png</td>\n",
       "      <td>0</td>\n",
       "      <td>data/data/7005867.png</td>\n",
       "      <td>[[0.019909676, 0.020805862, 0.034866877, 0.052...</td>\n",
       "      <td>[[0.019909676, 0.020805862, 0.011337465, -0.06...</td>\n",
       "      <td>[[0.021528233, 0.023085557, 0.038397443, 0.057...</td>\n",
       "      <td>[[0.021528233, 0.023085557, 0.01486803, -0.056...</td>\n",
       "      <td>[[0.03838063, 0.04409813, 0.057933092, 0.07251...</td>\n",
       "      <td>[[0.03838063, 0.04409813, 0.03440368, -0.04121...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, -0.023529412, -0.0235294...</td>\n",
       "      <td>[[0.026406609, 0.028926425, 0.044291265, 0.044...</td>\n",
       "      <td>[[0.026406609, 0.028926425, 0.044291265, 0.044...</td>\n",
       "      <td>[[0.05270214, 0.05708629, 0.05802837, 0.078446...</td>\n",
       "      <td>[[0.05270214, 0.05708629, 0.05802837, 0.078446...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6847606.png</td>\n",
       "      <td>0</td>\n",
       "      <td>data/data/6847606.png</td>\n",
       "      <td>[[0.0188342, 0.015733546, 0.025393154, 0.04027...</td>\n",
       "      <td>[[0.0188342, 0.015733546, 0.025393154, 0.01674...</td>\n",
       "      <td>[[0.019359432, 0.01708153, 0.027140666, 0.0432...</td>\n",
       "      <td>[[0.019359432, 0.01708153, 0.027140666, 0.0197...</td>\n",
       "      <td>[[0.03213664, 0.034240626, 0.04511521, 0.05878...</td>\n",
       "      <td>[[0.03213664, 0.034240626, 0.04511521, 0.03525...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.003921569, ...</td>\n",
       "      <td>[[0.007432907, 0.004641678, 0.0017120203, 0.00...</td>\n",
       "      <td>[[0.007432907, 0.004641678, 0.0017120203, 0.00...</td>\n",
       "      <td>[[0.020323094, 0.020871565, 0.025175508, 0.034...</td>\n",
       "      <td>[[0.020323094, 0.020871565, 0.025175508, 0.034...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4656855.png</td>\n",
       "      <td>1</td>\n",
       "      <td>data/data/4656855.png</td>\n",
       "      <td>[[0.047677375, 0.08174259, 0.1257889, 0.158103...</td>\n",
       "      <td>[[-0.49222872, -0.47694284, -0.40003267, -0.29...</td>\n",
       "      <td>[[0.07091708, 0.12270764, 0.18051544, 0.221854...</td>\n",
       "      <td>[[-0.468989, -0.4359778, -0.34530613, -0.23354...</td>\n",
       "      <td>[[0.10213965, 0.13281164, 0.16514815, 0.191359...</td>\n",
       "      <td>[[-0.43776643, -0.4258738, -0.36067343, -0.264...</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[[-0.53488374, -0.53953487, -0.5534884, -0.520...</td>\n",
       "      <td>[[0.21051943, 0.26774514, 0.29923058, 0.348166...</td>\n",
       "      <td>[[-0.3243643, -0.27178973, -0.2542578, -0.1727...</td>\n",
       "      <td>[[0.23558578, 0.26591277, 0.24990481, 0.334158...</td>\n",
       "      <td>[[-0.29929796, -0.2736221, -0.30358356, -0.186...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      image_id  label                   path  \\\n",
       "0  7005867.png      0  data/data/7005867.png   \n",
       "1  6847606.png      0  data/data/6847606.png   \n",
       "2  4656855.png      1  data/data/4656855.png   \n",
       "\n",
       "                             outputs_256_to_128_norm  \\\n",
       "0  [[0.019909676, 0.020805862, 0.034866877, 0.052...   \n",
       "1  [[0.0188342, 0.015733546, 0.025393154, 0.04027...   \n",
       "2  [[0.047677375, 0.08174259, 0.1257889, 0.158103...   \n",
       "\n",
       "                              erreur_256_to_128_norm  \\\n",
       "0  [[0.019909676, 0.020805862, 0.011337465, -0.06...   \n",
       "1  [[0.0188342, 0.015733546, 0.025393154, 0.01674...   \n",
       "2  [[-0.49222872, -0.47694284, -0.40003267, -0.29...   \n",
       "\n",
       "                           outputs_256_to_128_pneumo  \\\n",
       "0  [[0.021528233, 0.023085557, 0.038397443, 0.057...   \n",
       "1  [[0.019359432, 0.01708153, 0.027140666, 0.0432...   \n",
       "2  [[0.07091708, 0.12270764, 0.18051544, 0.221854...   \n",
       "\n",
       "                            erreur_256_to_128_pneumo  \\\n",
       "0  [[0.021528233, 0.023085557, 0.01486803, -0.056...   \n",
       "1  [[0.019359432, 0.01708153, 0.027140666, 0.0197...   \n",
       "2  [[-0.468989, -0.4359778, -0.34530613, -0.23354...   \n",
       "\n",
       "                            outputs_256_to_128_covid  \\\n",
       "0  [[0.03838063, 0.04409813, 0.057933092, 0.07251...   \n",
       "1  [[0.03213664, 0.034240626, 0.04511521, 0.05878...   \n",
       "2  [[0.10213965, 0.13281164, 0.16514815, 0.191359...   \n",
       "\n",
       "                             erreur_256_to_128_covid  \\\n",
       "0  [[0.03838063, 0.04409813, 0.03440368, -0.04121...   \n",
       "1  [[0.03213664, 0.034240626, 0.04511521, 0.03525...   \n",
       "2  [[-0.43776643, -0.4258738, -0.36067343, -0.264...   \n",
       "\n",
       "                             outputs_128_to_256_norm  \\\n",
       "0  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "1  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "2  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "\n",
       "                              erreur_128_to_256_norm  \\\n",
       "0  [[0.0, 0.0, 0.0, 0.0, -0.023529412, -0.0235294...   \n",
       "1  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.003921569, ...   \n",
       "2  [[-0.53488374, -0.53953487, -0.5534884, -0.520...   \n",
       "\n",
       "                           outputs_128_to_256_pneumo  \\\n",
       "0  [[0.026406609, 0.028926425, 0.044291265, 0.044...   \n",
       "1  [[0.007432907, 0.004641678, 0.0017120203, 0.00...   \n",
       "2  [[0.21051943, 0.26774514, 0.29923058, 0.348166...   \n",
       "\n",
       "                            erreur_128_to_256_pneumo  \\\n",
       "0  [[0.026406609, 0.028926425, 0.044291265, 0.044...   \n",
       "1  [[0.007432907, 0.004641678, 0.0017120203, 0.00...   \n",
       "2  [[-0.3243643, -0.27178973, -0.2542578, -0.1727...   \n",
       "\n",
       "                            outputs_128_to_256_covid  \\\n",
       "0  [[0.05270214, 0.05708629, 0.05802837, 0.078446...   \n",
       "1  [[0.020323094, 0.020871565, 0.025175508, 0.034...   \n",
       "2  [[0.23558578, 0.26591277, 0.24990481, 0.334158...   \n",
       "\n",
       "                             erreur_128_to_256_covid  \n",
       "0  [[0.05270214, 0.05708629, 0.05802837, 0.078446...  \n",
       "1  [[0.020323094, 0.020871565, 0.025175508, 0.034...  \n",
       "2  [[-0.29929796, -0.2736221, -0.30358356, -0.186...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_modif.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "440890b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de lignes dans l'ensemble d'entraînement et de validation : 2927\n",
      "Nombre de lignes dans l'ensemble de test : 732\n",
      "Nombre de lignes dans l'ensemble d'entraînement : 2341\n",
      "Nombre de lignes dans l'ensemble de validation : 586\n"
     ]
    }
   ],
   "source": [
    "df_all_train, df_all_test = train_test_split(df_modif, test_size=0.2, random_state=168)\n",
    "train_all_df, val_all_df = train_test_split(df_all_train, test_size=0.2, random_state= 761)\n",
    "# Afficher le nombre de lignes de chaque ensemble de données\n",
    "print('Nombre de lignes dans l\\'ensemble d\\'entraînement et de validation :', len(df_all_train))\n",
    "print('Nombre de lignes dans l\\'ensemble de test :', len(df_all_test))\n",
    "print('Nombre de lignes dans l\\'ensemble d\\'entraînement :', len(train_all_df))\n",
    "print('Nombre de lignes dans l\\'ensemble de validation :', len(val_all_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78d98fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataGenerator_256_norm(Sequence):\n",
    "    \n",
    "    def __init__(self, df, batch_size, input_size=(256,256), shuffle=True):\n",
    "        self.df = df\n",
    "        self.batch_size = batch_size\n",
    "        self.input_size = input_size\n",
    "        self.shuffle = shuffle\n",
    "        self.num_classes = 3 \n",
    "        self.on_epoch_end()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.df) / self.batch_size))\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        batch_df = self.df[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        batch_pn_256 = np.zeros((len(batch_df), *self.input_size, 1))\n",
    "        batch_y = np.zeros((len(batch_df), self.num_classes))\n",
    "\n",
    "        for i, row in enumerate(batch_df.itertuples()):\n",
    "            \n",
    "            y_pred_norm_256 = self.df[\"outputs_128_to_256_norm\"][i]\n",
    "            #y_erreur_norm_256 = self.df[\"erreur_128_to_256_norm\"][i]\n",
    "            #pn_256 = np.resize(1000-(-y_pred_norm_256+y_erreur_norm_256), (*self.input_size,1))\n",
    "            pn_256 = np.resize(1000-(y_pred_norm_256),(*self.input_size,1))\n",
    "            pn_256 = self.augment_input(pn_256)\n",
    "            pn_256 = (pn_256- np.min(pn_256)) / (np.max(pn_256) - np.min(pn_256))\n",
    "            pn_256 = np.reshape(pn_256,(*(self.input_size),1)).astype('float32')  \n",
    "            \n",
    "            #rgb_img = np.zeros((pn_256.shape[0], pn_256.shape[1], 3), dtype=np.uint8)\n",
    "\n",
    "            # Replicate the grayscale channel to all three channels of the RGB image\n",
    "            #rgb_img[:,:,0] = pn_256\n",
    "            #rgb_img[:,:,1] = pn_256\n",
    "            #rgb_img[:,:,2] = pn_256\n",
    "\n",
    "            \n",
    "            # label encodé en one-hot\n",
    "            label = self.df[\"label\"][i]\n",
    "            y = np.zeros(self.num_classes)\n",
    "            y[label] = 1.0\n",
    "         \n",
    "\n",
    "            batch_pn_256[i] = pn_256\n",
    "            batch_y[i] = y\n",
    "        \n",
    "        return batch_pn_256, batch_y\n",
    "    \n",
    "    def augment_input(self,pn_256):\n",
    "    # Apply data augmentation to the input images x1 and x2\n",
    "        image_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "            rotation_range=20,  # rotation jusqu'à 30° \n",
    "            zoom_range=0.12,     # zoom juqu'à 10%\n",
    "            brightness_range=[0.85, 1.15], # luminosité impa\n",
    "            horizontal_flip=True,\n",
    "            fill_mode='nearest', # mode de completion de l'image modifié\n",
    "        )\n",
    "        seed = np.random.randint(0, 10000) # generate a random seed\n",
    "        pn_256 = image_generator.random_transform(pn_256, seed=seed)\n",
    "       \n",
    "        return  pn_256\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        # melange le dataframe à la fin de chaque epoch d'entrainement\n",
    "        if self.shuffle:\n",
    "            self.df = self.df.sample(frac=1)\n",
    "            \n",
    "class CustomDataGenerator_256_valid_norm(Sequence):\n",
    "    \n",
    "    def __init__(self, df, batch_size, input_size=(256,256), shuffle=False):\n",
    "        self.df = df\n",
    "        self.batch_size = batch_size\n",
    "        self.input_size = input_size\n",
    "        self.shuffle = shuffle\n",
    "        self.num_classes = 3 \n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.df) / self.batch_size))\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        batch_df = self.df[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        batch_pn_256 = np.zeros((len(batch_df), *self.input_size, 1))\n",
    "        batch_y = np.zeros((len(batch_df), self.num_classes))\n",
    "\n",
    "        for i, row in enumerate(batch_df.itertuples()):\n",
    "            \n",
    "            y_pred_norm_256 = self.df[\"outputs_128_to_256_norm\"][i]\n",
    "            #y_erreur_norm_256 = self.df[\"erreur_128_to_256_norm\"][i]\n",
    "            #pn_256 = np.resize(1000-(-y_pred_norm_256+y_erreur_norm_256), (*self.input_size,1))\n",
    "            pn_256 = np.resize(1000-(y_pred_norm_256),(*self.input_size,1))                      \n",
    "            pn_256 = (pn_256- np.min(pn_256)) / (np.max(pn_256) - np.min(pn_256))\n",
    "            pn_256 = np.reshape(pn_256,(*(self.input_size),1)).astype('float32') \n",
    "            \n",
    "            #rgb_img = np.zeros((pn_256.shape[0], pn_256.shape[1], 3), dtype=np.uint8)\n",
    "\n",
    "            # Replicate the grayscale channel to all three channels of the RGB image\n",
    "            #rgb_img[:,:,0] = pn_256\n",
    "            #rgb_img[:,:,1] = pn_256\n",
    "            #rgb_img[:,:,2] = pn_256\n",
    "\n",
    "            \n",
    "            # label encodé en one-hot\n",
    "            label = self.df[\"label\"][i]\n",
    "            y = np.zeros(self.num_classes)\n",
    "            y[label] = 1.0\n",
    "         \n",
    "\n",
    "            batch_pn_256[i] = pn_256\n",
    "            batch_y[i] = y\n",
    "        \n",
    "        return batch_pn_256, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3fa2745",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all_df = train_all_df.reset_index(drop= True)\n",
    "val_all_df = val_all_df.reset_index(drop= True)\n",
    "\n",
    "train_all_generator=CustomDataGenerator_256_norm(train_all_df, batch_size=32)\n",
    "valid_all_generator=CustomDataGenerator_256_valid_norm(val_all_df, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a1c89f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(layer_names):\n",
    "    inputs = Input(shape=(256, 256, 1), name=layer_names[0])\n",
    "\n",
    "    x = Conv2D(filters=32, kernel_size=2, padding='valid', kernel_initializer='he_normal', kernel_regularizer=l2(10), name=layer_names[1])(inputs)\n",
    "    x = BatchNormalization(name=layer_names[2])(x)\n",
    "    x = LeakyReLU(name=layer_names[3])(x)\n",
    "    x = MaxPooling2D(2, 2, name=layer_names[4])(x)\n",
    "\n",
    "    x = Conv2D(filters=64, kernel_size=3, padding='valid', kernel_initializer='he_normal', kernel_regularizer=l2(10), name=layer_names[5])(x)\n",
    "    x = BatchNormalization(name=layer_names[6])(x)\n",
    "    x = LeakyReLU(name=layer_names[7])(x)\n",
    "    x = MaxPooling2D(3, 3, name=layer_names[8])(x)\n",
    "\n",
    "    x = Conv2D(filters=256, kernel_size=3, padding='valid', kernel_initializer='he_normal', kernel_regularizer=l2(10), name=layer_names[9])(x)\n",
    "    x = BatchNormalization(name=layer_names[10])(x)\n",
    "    x = LeakyReLU(name=layer_names[11])(x)\n",
    "    x = MaxPooling2D(2, 2, name=layer_names[12])(x)\n",
    "\n",
    "    x = Flatten(name=layer_names[13])(x)\n",
    "    x = Dense(256, kernel_initializer='he_normal', kernel_regularizer=l2(10), name=layer_names[14])(x)\n",
    "    x = LeakyReLU(name=layer_names[15])(x)\n",
    "    x = Dropout(0.2, name=layer_names[16])(x)\n",
    "\n",
    "    x = Dense(128, kernel_initializer='he_normal', kernel_regularizer=l2(10), name=layer_names[17])(x)\n",
    "    x = LeakyReLU(name=layer_names[18])(x)\n",
    "    x = Dropout(0.25, name=layer_names[19])(x)\n",
    "\n",
    "    x = Dense(64, kernel_initializer='he_normal', kernel_regularizer=l2(10), name=layer_names[20])(x)\n",
    "    x = LeakyReLU(name=layer_names[21])(x)\n",
    "    x = Dropout(0.3, name=layer_names[22])(x)\n",
    "\n",
    "    x = Dense(32, kernel_initializer='he_normal', kernel_regularizer=l2(10), name=layer_names[23])(x)\n",
    "    x = LeakyReLU(name=layer_names[24])(x)\n",
    "    x = BatchNormalization(name=layer_names[25])(x)\n",
    "    x = Dropout(0.3, name=layer_names[26])(x)\n",
    "\n",
    "    outputs = Dense(3, activation='softmax', name=layer_names[27])(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6159e934",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_norm (InputLayer)     [(None, 256, 256, 1)]     0         \n",
      "                                                                 \n",
      " norm_1 (Conv2D)             (None, 255, 255, 32)      160       \n",
      "                                                                 \n",
      " norm_2 (BatchNormalization)  (None, 255, 255, 32)     128       \n",
      "                                                                 \n",
      " norm_3 (LeakyReLU)          (None, 255, 255, 32)      0         \n",
      "                                                                 \n",
      " norm_4 (MaxPooling2D)       (None, 127, 127, 32)      0         \n",
      "                                                                 \n",
      " norm_5 (Conv2D)             (None, 125, 125, 64)      18496     \n",
      "                                                                 \n",
      " norm_6 (BatchNormalization)  (None, 125, 125, 64)     256       \n",
      "                                                                 \n",
      " norm_7 (LeakyReLU)          (None, 125, 125, 64)      0         \n",
      "                                                                 \n",
      " norm_8 (MaxPooling2D)       (None, 41, 41, 64)        0         \n",
      "                                                                 \n",
      " norm_9 (Conv2D)             (None, 39, 39, 256)       147712    \n",
      "                                                                 \n",
      " norm_10 (BatchNormalization  (None, 39, 39, 256)      1024      \n",
      " )                                                               \n",
      "                                                                 \n",
      " norm_11 (LeakyReLU)         (None, 39, 39, 256)       0         \n",
      "                                                                 \n",
      " norm_12 (MaxPooling2D)      (None, 19, 19, 256)       0         \n",
      "                                                                 \n",
      " norm_13 (Flatten)           (None, 92416)             0         \n",
      "                                                                 \n",
      " norm_14 (Dense)             (None, 256)               23658752  \n",
      "                                                                 \n",
      " norm_15 (LeakyReLU)         (None, 256)               0         \n",
      "                                                                 \n",
      " norm_16 (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " norm_17 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " norm_18 (LeakyReLU)         (None, 128)               0         \n",
      "                                                                 \n",
      " norm_19 (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " norm_20 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " norm_21 (LeakyReLU)         (None, 64)                0         \n",
      "                                                                 \n",
      " norm_22 (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " norm_23 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " norm_24 (LeakyReLU)         (None, 32)                0         \n",
      "                                                                 \n",
      " norm_25 (BatchNormalization  (None, 32)               128       \n",
      " )                                                               \n",
      "                                                                 \n",
      " norm_26 (Dropout)           (None, 32)                0         \n",
      "                                                                 \n",
      " output_norm (Dense)         (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,869,987\n",
      "Trainable params: 23,869,219\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "layer_names_norm = ['input_norm'] + ['norm_{}'.format(i) for i in range(1, 27)] + ['output_norm']\n",
    "\n",
    "ChestX_norm= create_model(layer_names_norm)\n",
    "\n",
    "# Create Adamax optimizer with learning rate 0.00001 and momentum 0.9\n",
    "optimizer = Adamax(learning_rate=0.00001, beta_1=0.9)\n",
    "early_stop = EarlyStopping(monitor='val_accuracy', patience=15, verbose=1, restore_best_weights=True)\n",
    "ChestX_norm.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "ChestX_norm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b1eb3734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "74/74 [==============================] - 9s 107ms/step - loss: 16131.4365 - accuracy: 0.4135 - val_loss: 15562.0957 - val_accuracy: 0.5939\n",
      "Epoch 2/100\n",
      "74/74 [==============================] - 8s 104ms/step - loss: 15076.8496 - accuracy: 0.5100 - val_loss: 14605.3613 - val_accuracy: 0.5324\n",
      "Epoch 3/100\n",
      "74/74 [==============================] - 8s 104ms/step - loss: 14196.5723 - accuracy: 0.5378 - val_loss: 13798.7637 - val_accuracy: 0.5324\n",
      "Epoch 4/100\n",
      "74/74 [==============================] - 8s 104ms/step - loss: 13447.3535 - accuracy: 0.5369 - val_loss: 13098.4248 - val_accuracy: 0.5631\n",
      "Epoch 5/100\n",
      "74/74 [==============================] - 8s 104ms/step - loss: 12790.6016 - accuracy: 0.5267 - val_loss: 12491.2646 - val_accuracy: 0.5631\n",
      "Epoch 6/100\n",
      "74/74 [==============================] - 8s 104ms/step - loss: 12226.7744 - accuracy: 0.4947 - val_loss: 11961.4004 - val_accuracy: 0.6246\n",
      "Epoch 7/100\n",
      "74/74 [==============================] - 8s 104ms/step - loss: 11730.2139 - accuracy: 0.4934 - val_loss: 11499.0420 - val_accuracy: 0.5939\n",
      "Epoch 8/100\n",
      "74/74 [==============================] - 8s 104ms/step - loss: 11296.1191 - accuracy: 0.5023 - val_loss: 11095.1416 - val_accuracy: 0.6246\n",
      "Epoch 9/100\n",
      "74/74 [==============================] - 8s 104ms/step - loss: 10918.6592 - accuracy: 0.5211 - val_loss: 10741.1416 - val_accuracy: 0.6246\n",
      "Epoch 10/100\n",
      "74/74 [==============================] - 8s 105ms/step - loss: 10584.0508 - accuracy: 0.5032 - val_loss: 10430.5254 - val_accuracy: 0.6877\n",
      "Epoch 11/100\n",
      "74/74 [==============================] - 8s 104ms/step - loss: 10293.9297 - accuracy: 0.5348 - val_loss: 10155.3330 - val_accuracy: 0.6860\n",
      "Epoch 12/100\n",
      "74/74 [==============================] - 8s 104ms/step - loss: 10032.0049 - accuracy: 0.5288 - val_loss: 9910.1240 - val_accuracy: 0.6860\n",
      "Epoch 13/100\n",
      "74/74 [==============================] - 8s 104ms/step - loss: 9800.1885 - accuracy: 0.5792 - val_loss: 9689.0010 - val_accuracy: 0.7491\n",
      "Epoch 14/100\n",
      "74/74 [==============================] - 8s 105ms/step - loss: 9587.3281 - accuracy: 0.6194 - val_loss: 9487.5928 - val_accuracy: 0.6860\n",
      "Epoch 15/100\n",
      "74/74 [==============================] - 8s 104ms/step - loss: 9395.0283 - accuracy: 0.6459 - val_loss: 9302.0020 - val_accuracy: 0.7474\n",
      "Epoch 16/100\n",
      "74/74 [==============================] - 8s 104ms/step - loss: 9215.4033 - accuracy: 0.7065 - val_loss: 9129.4082 - val_accuracy: 0.7167\n",
      "Epoch 17/100\n",
      "74/74 [==============================] - 8s 104ms/step - loss: 9048.8057 - accuracy: 0.7356 - val_loss: 8966.7998 - val_accuracy: 0.7474\n",
      "Epoch 18/100\n",
      "74/74 [==============================] - 8s 104ms/step - loss: 8890.4395 - accuracy: 0.7920 - val_loss: 8812.1396 - val_accuracy: 0.7782\n",
      "Epoch 19/100\n",
      "74/74 [==============================] - 8s 104ms/step - loss: 8738.6191 - accuracy: 0.8313 - val_loss: 8663.8457 - val_accuracy: 0.7765\n",
      "Epoch 20/100\n",
      "74/74 [==============================] - 8s 104ms/step - loss: 8591.9414 - accuracy: 0.8872 - val_loss: 8520.2188 - val_accuracy: 0.8754\n",
      "Epoch 21/100\n",
      "74/74 [==============================] - 8s 105ms/step - loss: 8451.1475 - accuracy: 0.8684 - val_loss: 8381.2197 - val_accuracy: 0.9061\n",
      "Epoch 22/100\n",
      "74/74 [==============================] - 8s 104ms/step - loss: 8314.4521 - accuracy: 0.9180 - val_loss: 8245.2500 - val_accuracy: 0.9061\n",
      "Epoch 23/100\n",
      "74/74 [==============================] - 8s 104ms/step - loss: 8179.6846 - accuracy: 0.9235 - val_loss: 8112.0000 - val_accuracy: 0.8737\n",
      "Epoch 24/100\n",
      "74/74 [==============================] - 8s 104ms/step - loss: 8046.6074 - accuracy: 0.9423 - val_loss: 7980.9985 - val_accuracy: 0.8754\n",
      "Epoch 25/100\n",
      "74/74 [==============================] - 8s 104ms/step - loss: 7917.8882 - accuracy: 0.9282 - val_loss: 7852.3608 - val_accuracy: 0.8754\n",
      "Epoch 26/100\n",
      "74/74 [==============================] - 8s 104ms/step - loss: 7789.2822 - accuracy: 0.9423 - val_loss: 7725.9077 - val_accuracy: 0.9061\n",
      "Epoch 27/100\n",
      "74/74 [==============================] - 8s 105ms/step - loss: 7663.4795 - accuracy: 0.9650 - val_loss: 7601.2031 - val_accuracy: 0.9061\n",
      "Epoch 28/100\n",
      "74/74 [==============================] - 8s 104ms/step - loss: 7539.8384 - accuracy: 0.9607 - val_loss: 7478.4922 - val_accuracy: 0.8754\n",
      "Epoch 29/100\n",
      "74/74 [==============================] - 8s 104ms/step - loss: 7418.6938 - accuracy: 0.9577 - val_loss: 7357.5410 - val_accuracy: 0.9061\n",
      "Epoch 30/100\n",
      "74/74 [==============================] - 8s 104ms/step - loss: 7299.0908 - accuracy: 0.9590 - val_loss: 7238.4609 - val_accuracy: 0.9044\n",
      "Epoch 31/100\n",
      "74/74 [==============================] - 8s 104ms/step - loss: 7180.9023 - accuracy: 0.9697 - val_loss: 7121.0684 - val_accuracy: 0.8447\n",
      "Epoch 32/100\n",
      "74/74 [==============================] - 8s 104ms/step - loss: 7063.9663 - accuracy: 0.9633 - val_loss: 7005.5723 - val_accuracy: 0.8430\n",
      "Epoch 33/100\n",
      "74/74 [==============================] - 8s 104ms/step - loss: 6949.6226 - accuracy: 0.9727 - val_loss: 6891.6406 - val_accuracy: 0.9061\n",
      "Epoch 34/100\n",
      "74/74 [==============================] - 8s 104ms/step - loss: 6835.7266 - accuracy: 0.9539 - val_loss: 6779.5630 - val_accuracy: 0.8737\n",
      "Epoch 35/100\n",
      "74/74 [==============================] - 8s 104ms/step - loss: 6725.2944 - accuracy: 0.9692 - val_loss: 6669.1406 - val_accuracy: 0.9044\n",
      "Epoch 36/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 6615.5195 - accuracy: 0.9650Restoring model weights from the end of the best epoch: 21.\n",
      "74/74 [==============================] - 8s 107ms/step - loss: 6615.5195 - accuracy: 0.9650 - val_loss: 6560.3672 - val_accuracy: 0.9061\n",
      "Epoch 36: early stopping\n"
     ]
    }
   ],
   "source": [
    "history_ChestX_norm = ChestX_norm.fit(train_all_generator, epochs=100, validation_data=valid_all_generator, callbacks= early_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0b50eda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_liste=[]\n",
    "y_true_liste=[]\n",
    "y_pred_argmax_liste=[]\n",
    "df_all_test = df_all_test.reset_index(drop=True)\n",
    "\n",
    "for i in range(len(df_all_test[\"path\"])):\n",
    "    y_pred_norm_256 = df_all_test[\"outputs_128_to_256_norm\"][i]\n",
    "    #y_erreur_norm_256 = df_all_test[\"erreur_128_to_256_norm\"][i]\n",
    "    #pn_256 = np.resize(1000-(-y_pred_norm_256+y_erreur_norm_256), (*(256,256),1))\n",
    "    pn_256 = np.resize(1000-(y_pred_norm_256),(*(256,256),1))\n",
    "    pn_256 = (pn_256- np.min(pn_256)) / (np.max(pn_256) - np.min(pn_256))\n",
    "    pn_256 = np.reshape(pn_256,(*(256,256),1)).astype('float32') \n",
    "\n",
    "    \n",
    "    y= df_all_test[\"label\"][i]\n",
    "    y= np.resize(y, (1, 1))\n",
    "\n",
    "    batch_pn_256 = np.resize(pn_256, (1, *(256,256),1))\n",
    "    batch_y = y\n",
    "\n",
    "    y_pred = ChestX_norm.predict(batch_pn_256,verbose= 0)\n",
    "    y_pred_argmax = np.argmax(y_pred, axis=1)\n",
    "    y_pred_liste.extend(y_pred)\n",
    "    y_pred_argmax_liste.extend(y_pred_argmax)\n",
    "    y_true_liste.extend(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aecbf6e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col_0    0    1    2\n",
      "row_0               \n",
      "0      224   34    2\n",
      "1       14  227    6\n",
      "2       13   19  193\n"
     ]
    }
   ],
   "source": [
    "y_true_liste = np.reshape(y_true_liste, (732))\n",
    "y_pred_argmax_liste = np.reshape(y_pred_argmax_liste, (732))\n",
    "print(pd.crosstab(y_true_liste, y_pred_argmax_liste))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "92d2a91d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de lignes dans l'ensemble d'entraînement et de validation : 2927\n",
      "Nombre de lignes dans l'ensemble de test : 732\n",
      "Nombre de lignes dans l'ensemble d'entraînement : 2341\n",
      "Nombre de lignes dans l'ensemble de validation : 586\n"
     ]
    }
   ],
   "source": [
    "df_all_train, df_all_test = train_test_split(df_modif, test_size=0.2, random_state=168)\n",
    "train_all_df, val_all_df = train_test_split(df_all_train, test_size=0.2, random_state= 158)\n",
    "# Afficher le nombre de lignes de chaque ensemble de données\n",
    "print('Nombre de lignes dans l\\'ensemble d\\'entraînement et de validation :', len(df_all_train))\n",
    "print('Nombre de lignes dans l\\'ensemble de test :', len(df_all_test))\n",
    "print('Nombre de lignes dans l\\'ensemble d\\'entraînement :', len(train_all_df))\n",
    "print('Nombre de lignes dans l\\'ensemble de validation :', len(val_all_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f6bcd293",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataGenerator_256_pneumo(Sequence):\n",
    "    \n",
    "    def __init__(self, df, batch_size, input_size=(256,256), shuffle=True):\n",
    "        self.df = df\n",
    "        self.batch_size = batch_size\n",
    "        self.input_size = input_size\n",
    "        self.shuffle = shuffle\n",
    "        self.num_classes = 3 \n",
    "        self.on_epoch_end()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.df) / self.batch_size))\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        batch_df = self.df[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        batch_pn_256 = np.zeros((len(batch_df), *self.input_size, 1))\n",
    "        batch_y = np.zeros((len(batch_df), self.num_classes))\n",
    "\n",
    "        for i, row in enumerate(batch_df.itertuples()):\n",
    "            \n",
    "            y_pred_pneumo_256 = self.df[\"outputs_128_to_256_pneumo\"][i]\n",
    "            #y_erreur_pneumo_256 = self.df[\"erreur_128_to_256_pneumo\"][i]\n",
    "            #pn_256 = np.resize(1000-(-y_pred_pneumo_256+y_erreur_pneumo_256), (*self.input_size,1))\n",
    "            pn_256 = np.resize(1000-(y_pred_pneumo_256),(*self.input_size,1))\n",
    "            pn_256 = self.augment_input(pn_256)\n",
    "            pn_256 = (pn_256- np.min(pn_256)) / (np.max(pn_256) - np.min(pn_256))\n",
    "            pn_256 = np.reshape(pn_256,(*(self.input_size),1)).astype('float32')  \n",
    "            \n",
    "            #rgb_img = np.zeros((pn_256.shape[0], pn_256.shape[1], 3), dtype=np.uint8)\n",
    "\n",
    "            # Replicate the grayscale channel to all three channels of the RGB image\n",
    "            #rgb_img[:,:,0] = pn_256\n",
    "            #rgb_img[:,:,1] = pn_256\n",
    "            #rgb_img[:,:,2] = pn_256\n",
    "\n",
    "            \n",
    "            # label encodé en one-hot\n",
    "            label = self.df[\"label\"][i]\n",
    "            y = np.zeros(self.num_classes)\n",
    "            y[label] = 1.0\n",
    "         \n",
    "\n",
    "            batch_pn_256[i] = pn_256\n",
    "            batch_y[i] = y\n",
    "        \n",
    "        return batch_pn_256, batch_y\n",
    "    \n",
    "    def augment_input(self,pn_256):\n",
    "    # Apply data augmentation to the input images x1 and x2\n",
    "        image_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "            rotation_range=20,  # rotation jusqu'à 30° \n",
    "            zoom_range=0.12,     # zoom juqu'à 10%\n",
    "            brightness_range=[0.85, 1.15], # luminosité impa\n",
    "            horizontal_flip=True,\n",
    "            fill_mode='nearest', # mode de completion de l'image modifié\n",
    "        )\n",
    "        seed = np.random.randint(0, 10000) # generate a random seed\n",
    "        pn_256 = image_generator.random_transform(pn_256, seed=seed)\n",
    "       \n",
    "        return  pn_256\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        # melange le dataframe à la fin de chaque epoch d'entrainement\n",
    "        if self.shuffle:\n",
    "            self.df = self.df.sample(frac=1)\n",
    "            \n",
    "class CustomDataGenerator_256_valid_pneumo(Sequence):\n",
    "    \n",
    "    def __init__(self, df, batch_size, input_size=(256,256), shuffle=False):\n",
    "        self.df = df\n",
    "        self.batch_size = batch_size\n",
    "        self.input_size = input_size\n",
    "        self.shuffle = shuffle\n",
    "        self.num_classes = 3 \n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.df) / self.batch_size))\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        batch_df = self.df[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        batch_pn_256 = np.zeros((len(batch_df), *self.input_size, 1))\n",
    "        batch_y = np.zeros((len(batch_df), self.num_classes))\n",
    "\n",
    "        for i, row in enumerate(batch_df.itertuples()):\n",
    "            \n",
    "            y_pred_pneumo_256 = self.df[\"outputs_128_to_256_pneumo\"][i]\n",
    "            #y_erreur_pneumo_256 = self.df[\"erreur_128_to_256_pneumo\"][i]\n",
    "            #pn_256 = np.resize(1000-(-y_pred_pneumo_256+y_erreur_pneumo_256), (*self.input_size,1))\n",
    "            pn_256 = np.resize(1000-(y_pred_pneumo_256),(*self.input_size,1))                      \n",
    "            pn_256 = (pn_256- np.min(pn_256)) / (np.max(pn_256) - np.min(pn_256))\n",
    "            pn_256 = np.reshape(pn_256,(*(self.input_size),1)).astype('float32') \n",
    "            \n",
    "            #rgb_img = np.zeros((pn_256.shape[0], pn_256.shape[1], 3), dtype=np.uint8)\n",
    "\n",
    "            # Replicate the grayscale channel to all three channels of the RGB image\n",
    "            #rgb_img[:,:,0] = pn_256\n",
    "            #rgb_img[:,:,1] = pn_256\n",
    "            #rgb_img[:,:,2] = pn_256\n",
    "\n",
    "            \n",
    "            # label encodé en one-hot\n",
    "            label = self.df[\"label\"][i]\n",
    "            y = np.zeros(self.num_classes)\n",
    "            y[label] = 1.0\n",
    "         \n",
    "\n",
    "            batch_pn_256[i] = pn_256\n",
    "            batch_y[i] = y\n",
    "        \n",
    "        return batch_pn_256, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d7992f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all_df = train_all_df.reset_index(drop= True)\n",
    "val_all_df = val_all_df.reset_index(drop= True)\n",
    "\n",
    "train_all_generator=CustomDataGenerator_256_pneumo(train_all_df, batch_size=32)\n",
    "valid_all_generator=CustomDataGenerator_256_valid_pneumo(val_all_df, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6ef09525",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_pneumo (InputLayer)   [(None, 256, 256, 1)]     0         \n",
      "                                                                 \n",
      " pneumo_1 (Conv2D)           (None, 255, 255, 32)      160       \n",
      "                                                                 \n",
      " pneumo_2 (BatchNormalizatio  (None, 255, 255, 32)     128       \n",
      " n)                                                              \n",
      "                                                                 \n",
      " pneumo_3 (LeakyReLU)        (None, 255, 255, 32)      0         \n",
      "                                                                 \n",
      " pneumo_4 (MaxPooling2D)     (None, 127, 127, 32)      0         \n",
      "                                                                 \n",
      " pneumo_5 (Conv2D)           (None, 125, 125, 64)      18496     \n",
      "                                                                 \n",
      " pneumo_6 (BatchNormalizatio  (None, 125, 125, 64)     256       \n",
      " n)                                                              \n",
      "                                                                 \n",
      " pneumo_7 (LeakyReLU)        (None, 125, 125, 64)      0         \n",
      "                                                                 \n",
      " pneumo_8 (MaxPooling2D)     (None, 41, 41, 64)        0         \n",
      "                                                                 \n",
      " pneumo_9 (Conv2D)           (None, 39, 39, 256)       147712    \n",
      "                                                                 \n",
      " pneumo_10 (BatchNormalizati  (None, 39, 39, 256)      1024      \n",
      " on)                                                             \n",
      "                                                                 \n",
      " pneumo_11 (LeakyReLU)       (None, 39, 39, 256)       0         \n",
      "                                                                 \n",
      " pneumo_12 (MaxPooling2D)    (None, 19, 19, 256)       0         \n",
      "                                                                 \n",
      " pneumo_13 (Flatten)         (None, 92416)             0         \n",
      "                                                                 \n",
      " pneumo_14 (Dense)           (None, 256)               23658752  \n",
      "                                                                 \n",
      " pneumo_15 (LeakyReLU)       (None, 256)               0         \n",
      "                                                                 \n",
      " pneumo_16 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " pneumo_17 (Dense)           (None, 128)               32896     \n",
      "                                                                 \n",
      " pneumo_18 (LeakyReLU)       (None, 128)               0         \n",
      "                                                                 \n",
      " pneumo_19 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " pneumo_20 (Dense)           (None, 64)                8256      \n",
      "                                                                 \n",
      " pneumo_21 (LeakyReLU)       (None, 64)                0         \n",
      "                                                                 \n",
      " pneumo_22 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " pneumo_23 (Dense)           (None, 32)                2080      \n",
      "                                                                 \n",
      " pneumo_24 (LeakyReLU)       (None, 32)                0         \n",
      "                                                                 \n",
      " pneumo_25 (BatchNormalizati  (None, 32)               128       \n",
      " on)                                                             \n",
      "                                                                 \n",
      " pneumo_26 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " output_pneumo (Dense)       (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,869,987\n",
      "Trainable params: 23,869,219\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "layer_names_pneumo = ['input_pneumo'] + ['pneumo_{}'.format(i) for i in range(1, 27)] + ['output_pneumo']\n",
    "\n",
    "ChestX_pneumo= create_model(layer_names_pneumo)\n",
    "optimizer = Adamax(learning_rate=0.00001, beta_1=0.9)\n",
    "early_stop = EarlyStopping(monitor='val_accuracy', patience=10, verbose=1, restore_best_weights=True)\n",
    "ChestX_pneumo.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "ChestX_pneumo.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a9f125dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "74/74 [==============================] - 9s 109ms/step - loss: 15994.7881 - accuracy: 0.5023 - val_loss: 15451.4365 - val_accuracy: 0.4727\n",
      "Epoch 2/100\n",
      "74/74 [==============================] - 8s 107ms/step - loss: 14990.8076 - accuracy: 0.6138 - val_loss: 14529.8721 - val_accuracy: 0.6860\n",
      "Epoch 3/100\n",
      "74/74 [==============================] - 8s 107ms/step - loss: 14120.9941 - accuracy: 0.5720 - val_loss: 13722.8154 - val_accuracy: 0.6877\n",
      "Epoch 4/100\n",
      "74/74 [==============================] - 8s 105ms/step - loss: 13368.2314 - accuracy: 0.5681 - val_loss: 13015.3750 - val_accuracy: 0.7491\n",
      "Epoch 5/100\n",
      "74/74 [==============================] - 8s 104ms/step - loss: 12702.3164 - accuracy: 0.5451 - val_loss: 12397.3311 - val_accuracy: 0.7201\n",
      "Epoch 6/100\n",
      "74/74 [==============================] - 8s 105ms/step - loss: 12123.4082 - accuracy: 0.5139 - val_loss: 11856.8857 - val_accuracy: 0.8123\n",
      "Epoch 7/100\n",
      "74/74 [==============================] - 8s 104ms/step - loss: 11618.3291 - accuracy: 0.5459 - val_loss: 11384.5918 - val_accuracy: 0.8123\n",
      "Epoch 8/100\n",
      "74/74 [==============================] - 8s 104ms/step - loss: 11176.5186 - accuracy: 0.5455 - val_loss: 10971.6523 - val_accuracy: 0.7799\n",
      "Epoch 9/100\n",
      "74/74 [==============================] - 8s 104ms/step - loss: 10788.0029 - accuracy: 0.5434 - val_loss: 10610.0645 - val_accuracy: 0.7799\n",
      "Epoch 10/100\n",
      "74/74 [==============================] - 8s 104ms/step - loss: 10451.0068 - accuracy: 0.5634 - val_loss: 10292.3428 - val_accuracy: 0.7799\n",
      "Epoch 11/100\n",
      "74/74 [==============================] - 8s 104ms/step - loss: 10150.7334 - accuracy: 0.5630 - val_loss: 10011.9082 - val_accuracy: 0.8123\n",
      "Epoch 12/100\n",
      "74/74 [==============================] - 8s 105ms/step - loss: 9885.9492 - accuracy: 0.5861 - val_loss: 9762.4570 - val_accuracy: 0.8430\n",
      "Epoch 13/100\n",
      "74/74 [==============================] - 8s 105ms/step - loss: 9650.0029 - accuracy: 0.6181 - val_loss: 9538.6191 - val_accuracy: 0.8754\n",
      "Epoch 14/100\n",
      "74/74 [==============================] - 8s 104ms/step - loss: 9436.8496 - accuracy: 0.6531 - val_loss: 9335.5020 - val_accuracy: 0.8754\n",
      "Epoch 15/100\n",
      "74/74 [==============================] - 8s 105ms/step - loss: 9241.8379 - accuracy: 0.6741 - val_loss: 9149.4746 - val_accuracy: 0.9061\n",
      "Epoch 16/100\n",
      "74/74 [==============================] - 8s 104ms/step - loss: 9063.4004 - accuracy: 0.7061 - val_loss: 8976.5762 - val_accuracy: 0.8123\n",
      "Epoch 17/100\n",
      "74/74 [==============================] - 8s 104ms/step - loss: 8895.8408 - accuracy: 0.7582 - val_loss: 8814.0566 - val_accuracy: 0.8123\n",
      "Epoch 18/100\n",
      "74/74 [==============================] - 8s 104ms/step - loss: 8737.4170 - accuracy: 0.7954 - val_loss: 8659.7510 - val_accuracy: 0.8754\n",
      "Epoch 19/100\n",
      "74/74 [==============================] - 8s 104ms/step - loss: 8586.3037 - accuracy: 0.8526 - val_loss: 8512.0244 - val_accuracy: 0.8123\n",
      "Epoch 20/100\n",
      "74/74 [==============================] - 8s 104ms/step - loss: 8441.2529 - accuracy: 0.8864 - val_loss: 8369.5703 - val_accuracy: 0.9369\n",
      "Epoch 21/100\n",
      "74/74 [==============================] - 8s 104ms/step - loss: 8301.0205 - accuracy: 0.9022 - val_loss: 8231.1035 - val_accuracy: 0.8754\n",
      "Epoch 22/100\n",
      "74/74 [==============================] - 8s 104ms/step - loss: 8164.1162 - accuracy: 0.9475 - val_loss: 8095.6494 - val_accuracy: 0.8447\n",
      "Epoch 23/100\n",
      "74/74 [==============================] - 8s 104ms/step - loss: 8029.6128 - accuracy: 0.9530 - val_loss: 7962.9814 - val_accuracy: 0.8771\n",
      "Epoch 24/100\n",
      "74/74 [==============================] - 8s 104ms/step - loss: 7898.2236 - accuracy: 0.9731 - val_loss: 7832.6724 - val_accuracy: 0.8737\n",
      "Epoch 25/100\n",
      "74/74 [==============================] - 8s 104ms/step - loss: 7768.4697 - accuracy: 0.9752 - val_loss: 7704.5454 - val_accuracy: 0.9061\n",
      "Epoch 26/100\n",
      "74/74 [==============================] - 8s 104ms/step - loss: 7642.0400 - accuracy: 0.9671 - val_loss: 7578.5869 - val_accuracy: 0.8737\n",
      "Epoch 27/100\n",
      "74/74 [==============================] - 8s 104ms/step - loss: 7517.1270 - accuracy: 0.9791 - val_loss: 7454.5146 - val_accuracy: 0.9061\n",
      "Epoch 28/100\n",
      "74/74 [==============================] - 8s 104ms/step - loss: 7394.0728 - accuracy: 0.9821 - val_loss: 7332.3359 - val_accuracy: 0.8737\n",
      "Epoch 29/100\n",
      "74/74 [==============================] - 8s 104ms/step - loss: 7272.3467 - accuracy: 0.9765 - val_loss: 7212.1201 - val_accuracy: 0.8737\n",
      "Epoch 30/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 7153.3013 - accuracy: 0.9697Restoring model weights from the end of the best epoch: 20.\n",
      "74/74 [==============================] - 8s 104ms/step - loss: 7153.3013 - accuracy: 0.9697 - val_loss: 7093.7598 - val_accuracy: 0.8737\n",
      "Epoch 30: early stopping\n"
     ]
    }
   ],
   "source": [
    "history_ChestX_pneumo = ChestX_pneumo.fit(train_all_generator, epochs=100, validation_data=valid_all_generator, callbacks= early_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "36cdb9cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col_0    0    1    2\n",
      "row_0               \n",
      "0      211   41    8\n",
      "1       24  209   14\n",
      "2        6    8  211\n"
     ]
    }
   ],
   "source": [
    "y_pred_liste=[]\n",
    "y_true_liste=[]\n",
    "y_pred_argmax_liste=[]\n",
    "df_all_test = df_all_test.reset_index(drop=True)\n",
    "\n",
    "for i in range(len(df_all_test[\"path\"])):\n",
    "    y_pred_pneumo_256 = df_all_test[\"outputs_128_to_256_pneumo\"][i]\n",
    "    #y_erreur_pneumo_256 = df_all_test[\"erreur_128_to_256_pneumo\"][i]\n",
    "    #pn_256 = np.resize(1000-(-y_pred_pneumo_256+y_erreur_pneumo_256), (*(256,256),1))\n",
    "    pn_256 = np.resize(1000-(y_pred_pneumo_256),(*(256,256),1))\n",
    "    pn_256 = (pn_256- np.min(pn_256)) / (np.max(pn_256) - np.min(pn_256))\n",
    "    pn_256 = np.reshape(pn_256,(*(256,256),1)).astype('float32') \n",
    "\n",
    "    \n",
    "    y= df_all_test[\"label\"][i]\n",
    "    y= np.resize(y, (1, 1))\n",
    "\n",
    "    batch_pn_256 = np.resize(pn_256, (1, *(256,256),1))\n",
    "    batch_y = y\n",
    "\n",
    "    y_pred = ChestX_pneumo.predict(batch_pn_256,verbose= 0)\n",
    "    y_pred_argmax = np.argmax(y_pred, axis=1)\n",
    "    y_pred_liste.extend(y_pred)\n",
    "    y_pred_argmax_liste.extend(y_pred_argmax)\n",
    "    y_true_liste.extend(y)\n",
    "    \n",
    "y_true_liste = np.reshape(y_true_liste, (732))\n",
    "y_pred_argmax_liste = np.reshape(y_pred_argmax_liste, (732))\n",
    "print(pd.crosstab(y_true_liste, y_pred_argmax_liste))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "740ee542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de lignes dans l'ensemble d'entraînement et de validation : 2927\n",
      "Nombre de lignes dans l'ensemble de test : 732\n",
      "Nombre de lignes dans l'ensemble d'entraînement : 2341\n",
      "Nombre de lignes dans l'ensemble de validation : 586\n"
     ]
    }
   ],
   "source": [
    "df_all_train, df_all_test = train_test_split(df_modif, test_size=0.2, random_state=168)\n",
    "train_all_df, val_all_df = train_test_split(df_all_train, test_size=0.2, random_state= 370)\n",
    "# Afficher le nombre de lignes de chaque ensemble de données\n",
    "print('Nombre de lignes dans l\\'ensemble d\\'entraînement et de validation :', len(df_all_train))\n",
    "print('Nombre de lignes dans l\\'ensemble de test :', len(df_all_test))\n",
    "print('Nombre de lignes dans l\\'ensemble d\\'entraînement :', len(train_all_df))\n",
    "print('Nombre de lignes dans l\\'ensemble de validation :', len(val_all_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5b42050d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataGenerator_256_covid(Sequence):\n",
    "    \n",
    "    def __init__(self, df, batch_size, input_size=(256,256), shuffle=True):\n",
    "        self.df = df\n",
    "        self.batch_size = batch_size\n",
    "        self.input_size = input_size\n",
    "        self.shuffle = shuffle\n",
    "        self.num_classes = 3 \n",
    "        self.on_epoch_end()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.df) / self.batch_size))\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        batch_df = self.df[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        batch_pn_256 = np.zeros((len(batch_df), *self.input_size, 1))\n",
    "        batch_y = np.zeros((len(batch_df), self.num_classes))\n",
    "\n",
    "        for i, row in enumerate(batch_df.itertuples()):\n",
    "            \n",
    "            y_pred_covid_256 = self.df[\"outputs_128_to_256_covid\"][i]\n",
    "            #y_erreur_covid_256 = self.df[\"erreur_128_to_256_covid\"][i]\n",
    "            #pn_256 = np.resize(1000-(-y_pred_covid_256+y_erreur_covid_256), (*self.input_size,1))\n",
    "            pn_256 = np.resize(1000-(y_pred_covid_256),(*self.input_size,1))\n",
    "            pn_256 = self.augment_input(pn_256)\n",
    "            pn_256 = (pn_256- np.min(pn_256)) / (np.max(pn_256) - np.min(pn_256))\n",
    "            pn_256 = np.reshape(pn_256,(*(self.input_size),1)).astype('float32')  \n",
    "            \n",
    "            #rgb_img = np.zeros((pn_256.shape[0], pn_256.shape[1], 3), dtype=np.uint8)\n",
    "\n",
    "            # Replicate the grayscale channel to all three channels of the RGB image\n",
    "            #rgb_img[:,:,0] = pn_256\n",
    "            #rgb_img[:,:,1] = pn_256\n",
    "            #rgb_img[:,:,2] = pn_256\n",
    "\n",
    "            \n",
    "            # label encodé en one-hot\n",
    "            label = self.df[\"label\"][i]\n",
    "            y = np.zeros(self.num_classes)\n",
    "            y[label] = 1.0\n",
    "         \n",
    "\n",
    "            batch_pn_256[i] = pn_256\n",
    "            batch_y[i] = y\n",
    "        \n",
    "        return batch_pn_256, batch_y\n",
    "    \n",
    "    def augment_input(self,pn_256):\n",
    "    # Apply data augmentation to the input images x1 and x2\n",
    "        image_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "            rotation_range=20,  # rotation jusqu'à 30° \n",
    "            zoom_range=0.12,     # zoom juqu'à 10%\n",
    "            brightness_range=[0.85, 1.15], # luminosité impa\n",
    "            horizontal_flip=True,\n",
    "            fill_mode='nearest', # mode de completion de l'image modifié\n",
    "        )\n",
    "        seed = np.random.randint(0, 10000) # generate a random seed\n",
    "        pn_256 = image_generator.random_transform(pn_256, seed=seed)\n",
    "       \n",
    "        return  pn_256\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        # melange le dataframe à la fin de chaque epoch d'entrainement\n",
    "        if self.shuffle:\n",
    "            self.df = self.df.sample(frac=1)\n",
    "            \n",
    "class CustomDataGenerator_256_valid_covid(Sequence):\n",
    "    \n",
    "    def __init__(self, df, batch_size, input_size=(256,256), shuffle=False):\n",
    "        self.df = df\n",
    "        self.batch_size = batch_size\n",
    "        self.input_size = input_size\n",
    "        self.shuffle = shuffle\n",
    "        self.num_classes = 3 \n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.df) / self.batch_size))\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        batch_df = self.df[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        batch_pn_256 = np.zeros((len(batch_df), *self.input_size, 1))\n",
    "        batch_y = np.zeros((len(batch_df), self.num_classes))\n",
    "\n",
    "        for i, row in enumerate(batch_df.itertuples()):\n",
    "            \n",
    "            y_pred_covid_256 = self.df[\"outputs_128_to_256_covid\"][i]\n",
    "            #y_erreur_covid_256 = self.df[\"erreur_128_to_256_covid\"][i]\n",
    "            #pn_256 = np.resize(1000-(-y_pred_covid_256+y_erreur_covid_256), (*self.input_size,1))\n",
    "            pn_256 = np.resize(1000-(y_pred_covid_256),(*self.input_size,1))                      \n",
    "            pn_256 = (pn_256- np.min(pn_256)) / (np.max(pn_256) - np.min(pn_256))\n",
    "            pn_256 = np.reshape(pn_256,(*(self.input_size),1)).astype('float32') \n",
    "            \n",
    "            #rgb_img = np.zeros((pn_256.shape[0], pn_256.shape[1], 3), dtype=np.uint8)\n",
    "\n",
    "            # Replicate the grayscale channel to all three channels of the RGB image\n",
    "            #rgb_img[:,:,0] = pn_256\n",
    "            #rgb_img[:,:,1] = pn_256\n",
    "            #rgb_img[:,:,2] = pn_256\n",
    "\n",
    "            \n",
    "            # label encodé en one-hot\n",
    "            label = self.df[\"label\"][i]\n",
    "            y = np.zeros(self.num_classes)\n",
    "            y[label] = 1.0\n",
    "         \n",
    "\n",
    "            batch_pn_256[i] = pn_256\n",
    "            batch_y[i] = y\n",
    "        \n",
    "        return batch_pn_256, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4b2bc2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all_df = train_all_df.reset_index(drop= True)\n",
    "val_all_df = val_all_df.reset_index(drop= True)\n",
    "\n",
    "train_all_generator=CustomDataGenerator_256_covid(train_all_df, batch_size=32)\n",
    "valid_all_generator=CustomDataGenerator_256_valid_covid(val_all_df, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "73865e79",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_covid (InputLayer)    [(None, 256, 256, 1)]     0         \n",
      "                                                                 \n",
      " covid_1 (Conv2D)            (None, 255, 255, 32)      160       \n",
      "                                                                 \n",
      " covid_2 (BatchNormalization  (None, 255, 255, 32)     128       \n",
      " )                                                               \n",
      "                                                                 \n",
      " covid_3 (LeakyReLU)         (None, 255, 255, 32)      0         \n",
      "                                                                 \n",
      " covid_4 (MaxPooling2D)      (None, 127, 127, 32)      0         \n",
      "                                                                 \n",
      " covid_5 (Conv2D)            (None, 125, 125, 64)      18496     \n",
      "                                                                 \n",
      " covid_6 (BatchNormalization  (None, 125, 125, 64)     256       \n",
      " )                                                               \n",
      "                                                                 \n",
      " covid_7 (LeakyReLU)         (None, 125, 125, 64)      0         \n",
      "                                                                 \n",
      " covid_8 (MaxPooling2D)      (None, 41, 41, 64)        0         \n",
      "                                                                 \n",
      " covid_9 (Conv2D)            (None, 39, 39, 256)       147712    \n",
      "                                                                 \n",
      " covid_10 (BatchNormalizatio  (None, 39, 39, 256)      1024      \n",
      " n)                                                              \n",
      "                                                                 \n",
      " covid_11 (LeakyReLU)        (None, 39, 39, 256)       0         \n",
      "                                                                 \n",
      " covid_12 (MaxPooling2D)     (None, 19, 19, 256)       0         \n",
      "                                                                 \n",
      " covid_13 (Flatten)          (None, 92416)             0         \n",
      "                                                                 \n",
      " covid_14 (Dense)            (None, 256)               23658752  \n",
      "                                                                 \n",
      " covid_15 (LeakyReLU)        (None, 256)               0         \n",
      "                                                                 \n",
      " covid_16 (Dropout)          (None, 256)               0         \n",
      "                                                                 \n",
      " covid_17 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " covid_18 (LeakyReLU)        (None, 128)               0         \n",
      "                                                                 \n",
      " covid_19 (Dropout)          (None, 128)               0         \n",
      "                                                                 \n",
      " covid_20 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " covid_21 (LeakyReLU)        (None, 64)                0         \n",
      "                                                                 \n",
      " covid_22 (Dropout)          (None, 64)                0         \n",
      "                                                                 \n",
      " covid_23 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " covid_24 (LeakyReLU)        (None, 32)                0         \n",
      "                                                                 \n",
      " covid_25 (BatchNormalizatio  (None, 32)               128       \n",
      " n)                                                              \n",
      "                                                                 \n",
      " covid_26 (Dropout)          (None, 32)                0         \n",
      "                                                                 \n",
      " output_covid (Dense)        (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,869,987\n",
      "Trainable params: 23,869,219\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "layer_names_covid = ['input_covid'] + ['covid_{}'.format(i) for i in range(1, 27)] + ['output_covid']\n",
    "\n",
    "ChestX_covid= create_model(layer_names_covid)\n",
    "optimizer = Adamax(learning_rate=0.00001, beta_1=0.9)\n",
    "early_stop = EarlyStopping(monitor='val_accuracy', patience=10, verbose=1, restore_best_weights=True)\n",
    "ChestX_covid.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "ChestX_covid.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "49f49963",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "74/74 [==============================] - 9s 108ms/step - loss: 16133.7754 - accuracy: 0.5442 - val_loss: 15581.4727 - val_accuracy: 0.4061\n",
      "Epoch 2/100\n",
      "74/74 [==============================] - 8s 105ms/step - loss: 15098.1670 - accuracy: 0.5968 - val_loss: 14627.2803 - val_accuracy: 0.5939\n",
      "Epoch 3/100\n",
      "74/74 [==============================] - 8s 105ms/step - loss: 14217.8555 - accuracy: 0.6416 - val_loss: 13812.4238 - val_accuracy: 0.6263\n",
      "Epoch 4/100\n",
      "74/74 [==============================] - 8s 105ms/step - loss: 13457.0508 - accuracy: 0.6574 - val_loss: 13103.9521 - val_accuracy: 0.8123\n",
      "Epoch 5/100\n",
      "74/74 [==============================] - 8s 104ms/step - loss: 12791.1943 - accuracy: 0.6455 - val_loss: 12487.2480 - val_accuracy: 0.7833\n",
      "Epoch 6/100\n",
      "74/74 [==============================] - 8s 105ms/step - loss: 12214.9199 - accuracy: 0.6463 - val_loss: 11950.1279 - val_accuracy: 0.8140\n",
      "Epoch 7/100\n",
      "74/74 [==============================] - 8s 105ms/step - loss: 11713.1777 - accuracy: 0.6523 - val_loss: 11482.9092 - val_accuracy: 0.8447\n",
      "Epoch 8/100\n",
      "74/74 [==============================] - 8s 103ms/step - loss: 11277.6670 - accuracy: 0.6578 - val_loss: 11075.7285 - val_accuracy: 0.8447\n",
      "Epoch 9/100\n",
      "74/74 [==============================] - 8s 103ms/step - loss: 10897.3408 - accuracy: 0.6792 - val_loss: 10720.1191 - val_accuracy: 0.8123\n",
      "Epoch 10/100\n",
      "74/74 [==============================] - 8s 105ms/step - loss: 10563.1826 - accuracy: 0.7053 - val_loss: 10409.1230 - val_accuracy: 0.8140\n",
      "Epoch 11/100\n",
      "74/74 [==============================] - 8s 104ms/step - loss: 10270.1514 - accuracy: 0.7300 - val_loss: 10135.3467 - val_accuracy: 0.8140\n",
      "Epoch 12/100\n",
      "74/74 [==============================] - 8s 104ms/step - loss: 10012.5957 - accuracy: 0.7629 - val_loss: 9891.1250 - val_accuracy: 0.8123\n",
      "Epoch 13/100\n",
      "74/74 [==============================] - 8s 104ms/step - loss: 9780.6338 - accuracy: 0.8005 - val_loss: 9671.4482 - val_accuracy: 0.8447\n",
      "Epoch 14/100\n",
      "74/74 [==============================] - 8s 105ms/step - loss: 9571.7236 - accuracy: 0.8236 - val_loss: 9471.8408 - val_accuracy: 0.8771\n",
      "Epoch 15/100\n",
      "74/74 [==============================] - 8s 105ms/step - loss: 9379.6484 - accuracy: 0.8586 - val_loss: 9288.6865 - val_accuracy: 0.9078\n",
      "Epoch 16/100\n",
      "74/74 [==============================] - 8s 104ms/step - loss: 9202.5566 - accuracy: 0.9090 - val_loss: 9117.9355 - val_accuracy: 0.8447\n",
      "Epoch 17/100\n",
      "74/74 [==============================] - 8s 106ms/step - loss: 9037.4893 - accuracy: 0.9299 - val_loss: 8957.4492 - val_accuracy: 0.9386\n",
      "Epoch 18/100\n",
      "74/74 [==============================] - 8s 106ms/step - loss: 8881.2686 - accuracy: 0.9252 - val_loss: 8805.0742 - val_accuracy: 0.8447\n",
      "Epoch 19/100\n",
      "74/74 [==============================] - 8s 105ms/step - loss: 8732.0137 - accuracy: 0.9654 - val_loss: 8658.2793 - val_accuracy: 0.9078\n",
      "Epoch 20/100\n",
      "74/74 [==============================] - 8s 104ms/step - loss: 8588.1602 - accuracy: 0.9654 - val_loss: 8516.0273 - val_accuracy: 0.8140\n",
      "Epoch 21/100\n",
      "74/74 [==============================] - 8s 105ms/step - loss: 8446.9180 - accuracy: 0.9654 - val_loss: 8377.6992 - val_accuracy: 0.8754\n",
      "Epoch 22/100\n",
      "74/74 [==============================] - 8s 104ms/step - loss: 8310.1191 - accuracy: 0.9744 - val_loss: 8242.5059 - val_accuracy: 0.8464\n",
      "Epoch 23/100\n",
      "74/74 [==============================] - 8s 105ms/step - loss: 8176.6768 - accuracy: 0.9846 - val_loss: 8109.7544 - val_accuracy: 0.8447\n",
      "Epoch 24/100\n",
      "74/74 [==============================] - 8s 104ms/step - loss: 8045.0293 - accuracy: 0.9829 - val_loss: 7979.1680 - val_accuracy: 0.8140\n",
      "Epoch 25/100\n",
      "74/74 [==============================] - 8s 104ms/step - loss: 7915.9248 - accuracy: 0.9902 - val_loss: 7850.6904 - val_accuracy: 0.8447\n",
      "Epoch 26/100\n",
      "74/74 [==============================] - 8s 104ms/step - loss: 7788.5171 - accuracy: 0.9876 - val_loss: 7724.4351 - val_accuracy: 0.8754\n",
      "Epoch 27/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 7663.2065 - accuracy: 0.9846Restoring model weights from the end of the best epoch: 17.\n",
      "74/74 [==============================] - 8s 104ms/step - loss: 7663.2065 - accuracy: 0.9846 - val_loss: 7600.1904 - val_accuracy: 0.7833\n",
      "Epoch 27: early stopping\n"
     ]
    }
   ],
   "source": [
    "history_ChestX_covid = ChestX_covid.fit(train_all_generator, epochs=100, validation_data=valid_all_generator, callbacks= early_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0c537c04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col_0    0    1    2\n",
      "row_0               \n",
      "0      233   24    3\n",
      "1       27  219    1\n",
      "2       23   24  178\n"
     ]
    }
   ],
   "source": [
    "y_pred_liste=[]\n",
    "y_true_liste=[]\n",
    "y_pred_argmax_liste=[]\n",
    "df_all_test = df_all_test.reset_index(drop=True)\n",
    "\n",
    "for i in range(len(df_all_test[\"path\"])):\n",
    "    y_pred_covid_256 = df_all_test[\"outputs_128_to_256_covid\"][i]\n",
    "    #y_erreur_covid_256 = df_all_test[\"erreur_128_to_256_covid\"][i]\n",
    "    #pn_256 = np.resize(1000-(-y_pred_covid_256+y_erreur_covid_256), (*(256,256),1))\n",
    "    pn_256 = np.resize(1000-(y_pred_covid_256),(*(256,256),1))\n",
    "    pn_256 = (pn_256- np.min(pn_256)) / (np.max(pn_256) - np.min(pn_256))\n",
    "    pn_256 = np.reshape(pn_256,(*(256,256),1)).astype('float32') \n",
    "\n",
    "    \n",
    "    y= df_all_test[\"label\"][i]\n",
    "    y= np.resize(y, (1, 1))\n",
    "\n",
    "    batch_pn_256 = np.resize(pn_256, (1, *(256,256),1))\n",
    "    batch_y = y\n",
    "\n",
    "    y_pred = ChestX_covid.predict(batch_pn_256,verbose= 0)\n",
    "    y_pred_argmax = np.argmax(y_pred, axis=1)\n",
    "    y_pred_liste.extend(y_pred)\n",
    "    y_pred_argmax_liste.extend(y_pred_argmax)\n",
    "    y_true_liste.extend(y)\n",
    "    \n",
    "y_true_liste = np.reshape(y_true_liste, (732))\n",
    "y_pred_argmax_liste = np.reshape(y_pred_argmax_liste, (732))\n",
    "print(pd.crosstab(y_true_liste, y_pred_argmax_liste))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5a6943f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de lignes dans l'ensemble d'entraînement et de validation : 2927\n",
      "Nombre de lignes dans l'ensemble de test : 732\n",
      "Nombre de lignes dans l'ensemble d'entraînement : 2341\n",
      "Nombre de lignes dans l'ensemble de validation : 586\n"
     ]
    }
   ],
   "source": [
    "df_all_train, df_all_test = train_test_split(df_modif, test_size=0.2, random_state=168)\n",
    "train_all_df, val_all_df = train_test_split(df_all_train, test_size=0.2, random_state= 652)\n",
    "# Afficher le nombre de lignes de chaque ensemble de données\n",
    "print('Nombre de lignes dans l\\'ensemble d\\'entraînement et de validation :', len(df_all_train))\n",
    "print('Nombre de lignes dans l\\'ensemble de test :', len(df_all_test))\n",
    "print('Nombre de lignes dans l\\'ensemble d\\'entraînement :', len(train_all_df))\n",
    "print('Nombre de lignes dans l\\'ensemble de validation :', len(val_all_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d1c1e930",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataGenerator_256_err_covid(Sequence):\n",
    "    \n",
    "    def __init__(self, df, batch_size, input_size=(256,256), shuffle=True):\n",
    "        self.df = df\n",
    "        self.batch_size = batch_size\n",
    "        self.input_size = input_size\n",
    "        self.shuffle = shuffle\n",
    "        self.num_classes = 3 \n",
    "        self.on_epoch_end()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.df) / self.batch_size))\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        batch_df = self.df[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        batch_pn_256 = np.zeros((len(batch_df), *self.input_size, 1))\n",
    "        batch_y = np.zeros((len(batch_df), self.num_classes))\n",
    "\n",
    "        for i, row in enumerate(batch_df.itertuples()):\n",
    "            \n",
    "            #y_pred_covid_256 = self.df[\"outputs_128_to_256_covid\"][i]\n",
    "            y_erreur_covid_256 = self.df[\"erreur_128_to_256_covid\"][i]\n",
    "            #pn_256 = np.resize(1000-(-y_pred_covid_256+y_erreur_covid_256), (*self.input_size,1))\n",
    "            pn_256 = np.resize(1000-(y_erreur_covid_256),(*self.input_size,1))\n",
    "            pn_256 = self.augment_input(pn_256)\n",
    "            pn_256 = (pn_256- np.min(pn_256)) / (np.max(pn_256) - np.min(pn_256))\n",
    "            pn_256 = np.reshape(pn_256,(*(self.input_size),1)).astype('float32')  \n",
    "            \n",
    "            #rgb_img = np.zeros((pn_256.shape[0], pn_256.shape[1], 3), dtype=np.uint8)\n",
    "\n",
    "            # Replicate the grayscale channel to all three channels of the RGB image\n",
    "            #rgb_img[:,:,0] = pn_256\n",
    "            #rgb_img[:,:,1] = pn_256\n",
    "            #rgb_img[:,:,2] = pn_256\n",
    "\n",
    "            \n",
    "            # label encodé en one-hot\n",
    "            label = self.df[\"label\"][i]\n",
    "            y = np.zeros(self.num_classes)\n",
    "            y[label] = 1.0\n",
    "         \n",
    "\n",
    "            batch_pn_256[i] = pn_256\n",
    "            batch_y[i] = y\n",
    "        \n",
    "        return batch_pn_256, batch_y\n",
    "    \n",
    "    def augment_input(self,pn_256):\n",
    "    # Apply data augmentation to the input images x1 and x2\n",
    "        image_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "            rotation_range=20,  # rotation jusqu'à 30° \n",
    "            zoom_range=0.12,     # zoom juqu'à 10%\n",
    "            brightness_range=[0.85, 1.15], # luminosité impa\n",
    "            horizontal_flip=True,\n",
    "            fill_mode='nearest', # mode de completion de l'image modifié\n",
    "        )\n",
    "        seed = np.random.randint(0, 10000) # generate a random seed\n",
    "        pn_256 = image_generator.random_transform(pn_256, seed=seed)\n",
    "       \n",
    "        return  pn_256\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        # melange le dataframe à la fin de chaque epoch d'entrainement\n",
    "        if self.shuffle:\n",
    "            self.df = self.df.sample(frac=1)\n",
    "            \n",
    "class CustomDataGenerator_256_valid_err_covid(Sequence):\n",
    "    \n",
    "    def __init__(self, df, batch_size, input_size=(256,256), shuffle=False):\n",
    "        self.df = df\n",
    "        self.batch_size = batch_size\n",
    "        self.input_size = input_size\n",
    "        self.shuffle = shuffle\n",
    "        self.num_classes = 3 \n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.df) / self.batch_size))\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        batch_df = self.df[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        batch_pn_256 = np.zeros((len(batch_df), *self.input_size, 1))\n",
    "        batch_y = np.zeros((len(batch_df), self.num_classes))\n",
    "\n",
    "        for i, row in enumerate(batch_df.itertuples()):\n",
    "            \n",
    "            #y_pred_covid_256 = self.df[\"outputs_128_to_256_covid\"][i]\n",
    "            y_erreur_covid_256 = self.df[\"erreur_128_to_256_covid\"][i]\n",
    "            #pn_256 = np.resize(1000-(-y_pred_covid_256+y_erreur_covid_256), (*self.input_size,1))\n",
    "            pn_256 = np.resize(1000-(y_erreur_covid_256),(*self.input_size,1))                      \n",
    "            pn_256 = (pn_256- np.min(pn_256)) / (np.max(pn_256) - np.min(pn_256))\n",
    "            pn_256 = np.reshape(pn_256,(*(self.input_size),1)).astype('float32') \n",
    "            \n",
    "            #rgb_img = np.zeros((pn_256.shape[0], pn_256.shape[1], 3), dtype=np.uint8)\n",
    "\n",
    "            # Replicate the grayscale channel to all three channels of the RGB image\n",
    "            #rgb_img[:,:,0] = pn_256\n",
    "            #rgb_img[:,:,1] = pn_256\n",
    "            #rgb_img[:,:,2] = pn_256\n",
    "\n",
    "            \n",
    "            # label encodé en one-hot\n",
    "            label = self.df[\"label\"][i]\n",
    "            y = np.zeros(self.num_classes)\n",
    "            y[label] = 1.0\n",
    "         \n",
    "\n",
    "            batch_pn_256[i] = pn_256\n",
    "            batch_y[i] = y\n",
    "        \n",
    "        return batch_pn_256, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "166136a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all_df = train_all_df.reset_index(drop= True)\n",
    "val_all_df = val_all_df.reset_index(drop= True)\n",
    "\n",
    "train_all_generator=CustomDataGenerator_256_err_covid(train_all_df, batch_size=32)\n",
    "valid_all_generator=CustomDataGenerator_256_valid_err_covid(val_all_df, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d9e329af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_err_covid (InputLayer  [(None, 256, 256, 1)]    0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " err_covid_1 (Conv2D)        (None, 255, 255, 32)      160       \n",
      "                                                                 \n",
      " err_covid_2 (BatchNormaliza  (None, 255, 255, 32)     128       \n",
      " tion)                                                           \n",
      "                                                                 \n",
      " err_covid_3 (LeakyReLU)     (None, 255, 255, 32)      0         \n",
      "                                                                 \n",
      " err_covid_4 (MaxPooling2D)  (None, 127, 127, 32)      0         \n",
      "                                                                 \n",
      " err_covid_5 (Conv2D)        (None, 125, 125, 64)      18496     \n",
      "                                                                 \n",
      " err_covid_6 (BatchNormaliza  (None, 125, 125, 64)     256       \n",
      " tion)                                                           \n",
      "                                                                 \n",
      " err_covid_7 (LeakyReLU)     (None, 125, 125, 64)      0         \n",
      "                                                                 \n",
      " err_covid_8 (MaxPooling2D)  (None, 41, 41, 64)        0         \n",
      "                                                                 \n",
      " err_covid_9 (Conv2D)        (None, 39, 39, 256)       147712    \n",
      "                                                                 \n",
      " err_covid_10 (BatchNormaliz  (None, 39, 39, 256)      1024      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " err_covid_11 (LeakyReLU)    (None, 39, 39, 256)       0         \n",
      "                                                                 \n",
      " err_covid_12 (MaxPooling2D)  (None, 19, 19, 256)      0         \n",
      "                                                                 \n",
      " err_covid_13 (Flatten)      (None, 92416)             0         \n",
      "                                                                 \n",
      " err_covid_14 (Dense)        (None, 256)               23658752  \n",
      "                                                                 \n",
      " err_covid_15 (LeakyReLU)    (None, 256)               0         \n",
      "                                                                 \n",
      " err_covid_16 (Dropout)      (None, 256)               0         \n",
      "                                                                 \n",
      " err_covid_17 (Dense)        (None, 128)               32896     \n",
      "                                                                 \n",
      " err_covid_18 (LeakyReLU)    (None, 128)               0         \n",
      "                                                                 \n",
      " err_covid_19 (Dropout)      (None, 128)               0         \n",
      "                                                                 \n",
      " err_covid_20 (Dense)        (None, 64)                8256      \n",
      "                                                                 \n",
      " err_covid_21 (LeakyReLU)    (None, 64)                0         \n",
      "                                                                 \n",
      " err_covid_22 (Dropout)      (None, 64)                0         \n",
      "                                                                 \n",
      " err_covid_23 (Dense)        (None, 32)                2080      \n",
      "                                                                 \n",
      " err_covid_24 (LeakyReLU)    (None, 32)                0         \n",
      "                                                                 \n",
      " err_covid_25 (BatchNormaliz  (None, 32)               128       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " err_covid_26 (Dropout)      (None, 32)                0         \n",
      "                                                                 \n",
      " output_err_covid (Dense)    (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,869,987\n",
      "Trainable params: 23,869,219\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "layer_names_err_covid = ['input_err_covid'] + ['err_covid_{}'.format(i) for i in range(1, 27)] + ['output_err_covid']\n",
    "\n",
    "ChestX_err_covid= create_model(layer_names_err_covid)\n",
    "optimizer = Adamax(learning_rate=0.00001, beta_1=0.9)\n",
    "early_stop = EarlyStopping(monitor='val_accuracy', patience=10, verbose=1, restore_best_weights=True)\n",
    "ChestX_err_covid.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "ChestX_err_covid.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5a205954",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "74/74 [==============================] - 9s 107ms/step - loss: 16111.9111 - accuracy: 0.4361 - val_loss: 15573.0430 - val_accuracy: 0.2850\n",
      "Epoch 2/100\n",
      "74/74 [==============================] - 8s 104ms/step - loss: 15102.3037 - accuracy: 0.4737 - val_loss: 14640.5869 - val_accuracy: 0.2850\n",
      "Epoch 3/100\n",
      "74/74 [==============================] - 8s 106ms/step - loss: 14231.9180 - accuracy: 0.4925 - val_loss: 13827.6230 - val_accuracy: 0.2850\n",
      "Epoch 4/100\n",
      "74/74 [==============================] - 9s 115ms/step - loss: 13472.4268 - accuracy: 0.4823 - val_loss: 13116.6230 - val_accuracy: 0.2833\n",
      "Epoch 5/100\n",
      "74/74 [==============================] - 8s 103ms/step - loss: 12802.8037 - accuracy: 0.4900 - val_loss: 12494.7734 - val_accuracy: 0.3140\n",
      "Epoch 6/100\n",
      "74/74 [==============================] - 8s 110ms/step - loss: 12222.1758 - accuracy: 0.4507 - val_loss: 11951.9512 - val_accuracy: 0.3430\n",
      "Epoch 7/100\n",
      "74/74 [==============================] - 8s 112ms/step - loss: 11712.2832 - accuracy: 0.4511 - val_loss: 11480.2334 - val_accuracy: 0.4386\n",
      "Epoch 8/100\n",
      "74/74 [==============================] - 8s 107ms/step - loss: 11272.1699 - accuracy: 0.4810 - val_loss: 11068.7129 - val_accuracy: 0.4693\n",
      "Epoch 9/100\n",
      "74/74 [==============================] - 8s 110ms/step - loss: 10887.6826 - accuracy: 0.4823 - val_loss: 10708.7324 - val_accuracy: 0.4693\n",
      "Epoch 10/100\n",
      "74/74 [==============================] - 8s 107ms/step - loss: 10549.3359 - accuracy: 0.4853 - val_loss: 10393.1094 - val_accuracy: 0.5324\n",
      "Epoch 11/100\n",
      "74/74 [==============================] - 8s 105ms/step - loss: 10254.4629 - accuracy: 0.5164 - val_loss: 10114.5928 - val_accuracy: 0.4676\n",
      "Epoch 12/100\n",
      "74/74 [==============================] - 8s 105ms/step - loss: 9991.0293 - accuracy: 0.5369 - val_loss: 9867.8105 - val_accuracy: 0.4693\n",
      "Epoch 13/100\n",
      "74/74 [==============================] - 8s 104ms/step - loss: 9756.1729 - accuracy: 0.5694 - val_loss: 9645.6250 - val_accuracy: 0.5017\n",
      "Epoch 14/100\n",
      "74/74 [==============================] - 8s 104ms/step - loss: 9545.6328 - accuracy: 0.5946 - val_loss: 9443.7705 - val_accuracy: 0.4693\n",
      "Epoch 15/100\n",
      "74/74 [==============================] - 8s 105ms/step - loss: 9350.9072 - accuracy: 0.6369 - val_loss: 9258.2129 - val_accuracy: 0.5648\n",
      "Epoch 16/100\n",
      "74/74 [==============================] - 8s 105ms/step - loss: 9172.5391 - accuracy: 0.6835 - val_loss: 9086.0068 - val_accuracy: 0.5631\n",
      "Epoch 17/100\n",
      "74/74 [==============================] - 8s 104ms/step - loss: 9005.8672 - accuracy: 0.7710 - val_loss: 8924.4160 - val_accuracy: 0.5000\n",
      "Epoch 18/100\n",
      "74/74 [==============================] - 8s 105ms/step - loss: 8848.3213 - accuracy: 0.7864 - val_loss: 8771.5322 - val_accuracy: 0.4983\n",
      "Epoch 19/100\n",
      "74/74 [==============================] - 8s 105ms/step - loss: 8698.4062 - accuracy: 0.8411 - val_loss: 8624.8467 - val_accuracy: 0.5939\n",
      "Epoch 20/100\n",
      "74/74 [==============================] - 8s 103ms/step - loss: 8553.7803 - accuracy: 0.8718 - val_loss: 8482.7256 - val_accuracy: 0.5939\n",
      "Epoch 21/100\n",
      "74/74 [==============================] - 8s 103ms/step - loss: 8414.2910 - accuracy: 0.8830 - val_loss: 8343.9521 - val_accuracy: 0.5939\n",
      "Epoch 22/100\n",
      "74/74 [==============================] - 8s 103ms/step - loss: 8275.9785 - accuracy: 0.8992 - val_loss: 8208.7402 - val_accuracy: 0.6246\n",
      "Epoch 23/100\n",
      "74/74 [==============================] - 8s 103ms/step - loss: 8142.3296 - accuracy: 0.9188 - val_loss: 8075.8022 - val_accuracy: 0.5000\n",
      "Epoch 24/100\n",
      "74/74 [==============================] - 8s 105ms/step - loss: 8009.9292 - accuracy: 0.9287 - val_loss: 7945.1196 - val_accuracy: 0.5939\n",
      "Epoch 25/100\n",
      "74/74 [==============================] - 8s 105ms/step - loss: 7880.7510 - accuracy: 0.9423 - val_loss: 7816.9146 - val_accuracy: 0.5000\n",
      "Epoch 26/100\n",
      "74/74 [==============================] - 8s 105ms/step - loss: 7753.1826 - accuracy: 0.9569 - val_loss: 7690.3823 - val_accuracy: 0.5956\n",
      "Epoch 27/100\n",
      "74/74 [==============================] - 8s 105ms/step - loss: 7627.4556 - accuracy: 0.9496 - val_loss: 7565.7349 - val_accuracy: 0.5939\n",
      "Epoch 28/100\n",
      "74/74 [==============================] - 8s 105ms/step - loss: 7504.6162 - accuracy: 0.9509 - val_loss: 7443.2988 - val_accuracy: 0.5922\n",
      "Epoch 29/100\n",
      "74/74 [==============================] - 8s 104ms/step - loss: 7382.5586 - accuracy: 0.9598 - val_loss: 7322.8267 - val_accuracy: 0.6246\n",
      "Epoch 30/100\n",
      "74/74 [==============================] - 8s 105ms/step - loss: 7263.3047 - accuracy: 0.9539 - val_loss: 7204.0615 - val_accuracy: 0.5939\n",
      "Epoch 31/100\n",
      "74/74 [==============================] - 8s 105ms/step - loss: 7144.8398 - accuracy: 0.9663 - val_loss: 7086.9609 - val_accuracy: 0.5631\n",
      "Epoch 32/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 7028.8208 - accuracy: 0.9641Restoring model weights from the end of the best epoch: 22.\n",
      "74/74 [==============================] - 8s 105ms/step - loss: 7028.8208 - accuracy: 0.9641 - val_loss: 6971.5928 - val_accuracy: 0.5648\n",
      "Epoch 32: early stopping\n"
     ]
    }
   ],
   "source": [
    "history_ChestX_err_covid = ChestX_err_covid.fit(train_all_generator, epochs=100, validation_data=valid_all_generator, callbacks= early_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dd3548cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col_0    0    1    2\n",
      "row_0               \n",
      "0      136  121    3\n",
      "1      112  130    5\n",
      "2       65   10  150\n"
     ]
    }
   ],
   "source": [
    "y_pred_liste=[]\n",
    "y_true_liste=[]\n",
    "y_pred_argmax_liste=[]\n",
    "df_all_test = df_all_test.reset_index(drop=True)\n",
    "\n",
    "for i in range(len(df_all_test[\"path\"])):\n",
    "    #y_pred_covid_256 = df_all_test[\"outputs_128_to_256_covid\"][i]\n",
    "    y_erreur_covid_256 = df_all_test[\"erreur_128_to_256_covid\"][i]\n",
    "    #pn_256 = np.resize(1000-(-y_pred_covid_256+y_erreur_covid_256), (*(256,256),1))\n",
    "    pn_256 = np.resize(1000-(y_erreur_covid_256),(*(256,256),1))\n",
    "    pn_256 = (pn_256- np.min(pn_256)) / (np.max(pn_256) - np.min(pn_256))\n",
    "    pn_256 = np.reshape(pn_256,(*(256,256),1)).astype('float32') \n",
    "\n",
    "    \n",
    "    y= df_all_test[\"label\"][i]\n",
    "    y= np.resize(y, (1, 1))\n",
    "\n",
    "    batch_pn_256 = np.resize(pn_256, (1, *(256,256),1))\n",
    "    batch_y = y\n",
    "\n",
    "    y_pred = ChestX_err_covid.predict(batch_pn_256,verbose= 0)\n",
    "    y_pred_argmax = np.argmax(y_pred, axis=1)\n",
    "    y_pred_liste.extend(y_pred)\n",
    "    y_pred_argmax_liste.extend(y_pred_argmax)\n",
    "    y_true_liste.extend(y)\n",
    "    \n",
    "y_true_liste = np.reshape(y_true_liste, (732))\n",
    "y_pred_argmax_liste = np.reshape(y_pred_argmax_liste, (732))\n",
    "print(pd.crosstab(y_true_liste, y_pred_argmax_liste))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e3620a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de lignes dans l'ensemble d'entraînement et de validation : 2927\n",
      "Nombre de lignes dans l'ensemble de test : 732\n",
      "Nombre de lignes dans l'ensemble d'entraînement : 2341\n",
      "Nombre de lignes dans l'ensemble de validation : 586\n"
     ]
    }
   ],
   "source": [
    "df_all_train, df_all_test = train_test_split(df_modif, test_size=0.2, random_state=168)\n",
    "train_all_df, val_all_df = train_test_split(df_all_train, test_size=0.2, random_state= 798)\n",
    "# Afficher le nombre de lignes de chaque ensemble de données\n",
    "print('Nombre de lignes dans l\\'ensemble d\\'entraînement et de validation :', len(df_all_train))\n",
    "print('Nombre de lignes dans l\\'ensemble de test :', len(df_all_test))\n",
    "print('Nombre de lignes dans l\\'ensemble d\\'entraînement :', len(train_all_df))\n",
    "print('Nombre de lignes dans l\\'ensemble de validation :', len(val_all_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "81c9b3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataGenerator_256_err_norm(Sequence):\n",
    "    \n",
    "    def __init__(self, df, batch_size, input_size=(256,256), shuffle=True):\n",
    "        self.df = df\n",
    "        self.batch_size = batch_size\n",
    "        self.input_size = input_size\n",
    "        self.shuffle = shuffle\n",
    "        self.num_classes = 3 \n",
    "        self.on_epoch_end()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.df) / self.batch_size))\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        batch_df = self.df[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        batch_pn_256 = np.zeros((len(batch_df), *self.input_size, 1))\n",
    "        batch_y = np.zeros((len(batch_df), self.num_classes))\n",
    "\n",
    "        for i, row in enumerate(batch_df.itertuples()):\n",
    "            \n",
    "            #y_pred_norm_256 = self.df[\"outputs_128_to_256_norm\"][i]\n",
    "            y_erreur_norm_256 = self.df[\"erreur_128_to_256_norm\"][i]\n",
    "            #pn_256 = np.resize(1000-(-y_pred_norm_256+y_erreur_norm_256), (*self.input_size,1))\n",
    "            pn_256 = np.resize(1000-(y_erreur_norm_256),(*self.input_size,1))\n",
    "            pn_256 = self.augment_input(pn_256)\n",
    "            pn_256 = (pn_256- np.min(pn_256)) / (np.max(pn_256) - np.min(pn_256))\n",
    "            pn_256 = np.reshape(pn_256,(*(self.input_size),1)).astype('float32')  \n",
    "            \n",
    "            #rgb_img = np.zeros((pn_256.shape[0], pn_256.shape[1], 3), dtype=np.uint8)\n",
    "\n",
    "            # Replicate the grayscale channel to all three channels of the RGB image\n",
    "            #rgb_img[:,:,0] = pn_256\n",
    "            #rgb_img[:,:,1] = pn_256\n",
    "            #rgb_img[:,:,2] = pn_256\n",
    "\n",
    "            \n",
    "            # label encodé en one-hot\n",
    "            label = self.df[\"label\"][i]\n",
    "            y = np.zeros(self.num_classes)\n",
    "            y[label] = 1.0\n",
    "         \n",
    "\n",
    "            batch_pn_256[i] = pn_256\n",
    "            batch_y[i] = y\n",
    "        \n",
    "        return batch_pn_256, batch_y\n",
    "    \n",
    "    def augment_input(self,pn_256):\n",
    "    # Apply data augmentation to the input images x1 and x2\n",
    "        image_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "            rotation_range=20,  # rotation jusqu'à 30° \n",
    "            zoom_range=0.12,     # zoom juqu'à 10%\n",
    "            brightness_range=[0.85, 1.15], # luminosité impa\n",
    "            horizontal_flip=True,\n",
    "            fill_mode='nearest', # mode de completion de l'image modifié\n",
    "        )\n",
    "        seed = np.random.randint(0, 10000) # generate a random seed\n",
    "        pn_256 = image_generator.random_transform(pn_256, seed=seed)\n",
    "       \n",
    "        return  pn_256\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        # melange le dataframe à la fin de chaque epoch d'entrainement\n",
    "        if self.shuffle:\n",
    "            self.df = self.df.sample(frac=1)\n",
    "            \n",
    "class CustomDataGenerator_256_valid_err_norm(Sequence):\n",
    "    \n",
    "    def __init__(self, df, batch_size, input_size=(256,256), shuffle=False):\n",
    "        self.df = df\n",
    "        self.batch_size = batch_size\n",
    "        self.input_size = input_size\n",
    "        self.shuffle = shuffle\n",
    "        self.num_classes = 3 \n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.df) / self.batch_size))\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        batch_df = self.df[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        batch_pn_256 = np.zeros((len(batch_df), *self.input_size, 1))\n",
    "        batch_y = np.zeros((len(batch_df), self.num_classes))\n",
    "\n",
    "        for i, row in enumerate(batch_df.itertuples()):\n",
    "            \n",
    "            #y_pred_norm_256 = self.df[\"outputs_128_to_256_norm\"][i]\n",
    "            y_erreur_norm_256 = self.df[\"erreur_128_to_256_norm\"][i]\n",
    "            #pn_256 = np.resize(1000-(-y_pred_norm_256+y_erreur_norm_256), (*self.input_size,1))\n",
    "            pn_256 = np.resize(1000-(y_erreur_norm_256),(*self.input_size,1))                      \n",
    "            pn_256 = (pn_256- np.min(pn_256)) / (np.max(pn_256) - np.min(pn_256))\n",
    "            pn_256 = np.reshape(pn_256,(*(self.input_size),1)).astype('float32') \n",
    "            \n",
    "            #rgb_img = np.zeros((pn_256.shape[0], pn_256.shape[1], 3), dtype=np.uint8)\n",
    "\n",
    "            # Replicate the grayscale channel to all three channels of the RGB image\n",
    "            #rgb_img[:,:,0] = pn_256\n",
    "            #rgb_img[:,:,1] = pn_256\n",
    "            #rgb_img[:,:,2] = pn_256\n",
    "\n",
    "            \n",
    "            # label encodé en one-hot\n",
    "            label = self.df[\"label\"][i]\n",
    "            y = np.zeros(self.num_classes)\n",
    "            y[label] = 1.0\n",
    "         \n",
    "\n",
    "            batch_pn_256[i] = pn_256\n",
    "            batch_y[i] = y\n",
    "        \n",
    "        return batch_pn_256, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "59b99e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all_df = train_all_df.reset_index(drop= True)\n",
    "val_all_df = val_all_df.reset_index(drop= True)\n",
    "\n",
    "train_all_generator=CustomDataGenerator_256_err_norm(train_all_df, batch_size=32)\n",
    "valid_all_generator=CustomDataGenerator_256_valid_err_norm(val_all_df, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c8a5d078",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_err_norm (InputLayer)  [(None, 256, 256, 1)]    0         \n",
      "                                                                 \n",
      " err_norm_1 (Conv2D)         (None, 255, 255, 32)      160       \n",
      "                                                                 \n",
      " err_norm_2 (BatchNormalizat  (None, 255, 255, 32)     128       \n",
      " ion)                                                            \n",
      "                                                                 \n",
      " err_norm_3 (LeakyReLU)      (None, 255, 255, 32)      0         \n",
      "                                                                 \n",
      " err_norm_4 (MaxPooling2D)   (None, 127, 127, 32)      0         \n",
      "                                                                 \n",
      " err_norm_5 (Conv2D)         (None, 125, 125, 64)      18496     \n",
      "                                                                 \n",
      " err_norm_6 (BatchNormalizat  (None, 125, 125, 64)     256       \n",
      " ion)                                                            \n",
      "                                                                 \n",
      " err_norm_7 (LeakyReLU)      (None, 125, 125, 64)      0         \n",
      "                                                                 \n",
      " err_norm_8 (MaxPooling2D)   (None, 41, 41, 64)        0         \n",
      "                                                                 \n",
      " err_norm_9 (Conv2D)         (None, 39, 39, 256)       147712    \n",
      "                                                                 \n",
      " err_norm_10 (BatchNormaliza  (None, 39, 39, 256)      1024      \n",
      " tion)                                                           \n",
      "                                                                 \n",
      " err_norm_11 (LeakyReLU)     (None, 39, 39, 256)       0         \n",
      "                                                                 \n",
      " err_norm_12 (MaxPooling2D)  (None, 19, 19, 256)       0         \n",
      "                                                                 \n",
      " err_norm_13 (Flatten)       (None, 92416)             0         \n",
      "                                                                 \n",
      " err_norm_14 (Dense)         (None, 256)               23658752  \n",
      "                                                                 \n",
      " err_norm_15 (LeakyReLU)     (None, 256)               0         \n",
      "                                                                 \n",
      " err_norm_16 (Dropout)       (None, 256)               0         \n",
      "                                                                 \n",
      " err_norm_17 (Dense)         (None, 128)               32896     \n",
      "                                                                 \n",
      " err_norm_18 (LeakyReLU)     (None, 128)               0         \n",
      "                                                                 \n",
      " err_norm_19 (Dropout)       (None, 128)               0         \n",
      "                                                                 \n",
      " err_norm_20 (Dense)         (None, 64)                8256      \n",
      "                                                                 \n",
      " err_norm_21 (LeakyReLU)     (None, 64)                0         \n",
      "                                                                 \n",
      " err_norm_22 (Dropout)       (None, 64)                0         \n",
      "                                                                 \n",
      " err_norm_23 (Dense)         (None, 32)                2080      \n",
      "                                                                 \n",
      " err_norm_24 (LeakyReLU)     (None, 32)                0         \n",
      "                                                                 \n",
      " err_norm_25 (BatchNormaliza  (None, 32)               128       \n",
      " tion)                                                           \n",
      "                                                                 \n",
      " err_norm_26 (Dropout)       (None, 32)                0         \n",
      "                                                                 \n",
      " output_err_norm (Dense)     (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,869,987\n",
      "Trainable params: 23,869,219\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "layer_names_err_norm = ['input_err_norm'] + ['err_norm_{}'.format(i) for i in range(1, 27)] + ['output_err_norm']\n",
    "\n",
    "ChestX_err_norm= create_model(layer_names_err_norm)\n",
    "optimizer = Adamax(learning_rate=0.00001, beta_1=0.9)\n",
    "early_stop = EarlyStopping(monitor='val_accuracy', patience=10, verbose=1, restore_best_weights=True)\n",
    "ChestX_err_norm.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "ChestX_err_norm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e341e85d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "74/74 [==============================] - 9s 107ms/step - loss: 15971.3252 - accuracy: 0.4229 - val_loss: 15391.5615 - val_accuracy: 0.3447\n",
      "Epoch 2/100\n",
      "74/74 [==============================] - 8s 104ms/step - loss: 14901.5752 - accuracy: 0.5267 - val_loss: 14420.1162 - val_accuracy: 0.3447\n",
      "Epoch 3/100\n",
      "74/74 [==============================] - 8s 104ms/step - loss: 14001.9756 - accuracy: 0.5886 - val_loss: 13600.5791 - val_accuracy: 0.3447\n",
      "Epoch 4/100\n",
      "74/74 [==============================] - 8s 106ms/step - loss: 13246.2168 - accuracy: 0.6091 - val_loss: 12895.9521 - val_accuracy: 0.3754\n",
      "Epoch 5/100\n",
      "74/74 [==============================] - 8s 105ms/step - loss: 12593.3154 - accuracy: 0.6446 - val_loss: 12294.3867 - val_accuracy: 0.3754\n",
      "Epoch 6/100\n",
      "74/74 [==============================] - 8s 104ms/step - loss: 12028.0928 - accuracy: 0.6557 - val_loss: 11772.7764 - val_accuracy: 0.5648\n",
      "Epoch 7/100\n",
      "74/74 [==============================] - 8s 105ms/step - loss: 11544.3887 - accuracy: 0.6638 - val_loss: 11318.2207 - val_accuracy: 0.5973\n",
      "Epoch 8/100\n",
      "74/74 [==============================] - 8s 102ms/step - loss: 11116.5420 - accuracy: 0.6809 - val_loss: 10921.8887 - val_accuracy: 0.5358\n",
      "Epoch 9/100\n",
      "74/74 [==============================] - 8s 103ms/step - loss: 10747.1836 - accuracy: 0.6809 - val_loss: 10576.1670 - val_accuracy: 0.5358\n",
      "Epoch 10/100\n",
      "74/74 [==============================] - 8s 102ms/step - loss: 10423.7676 - accuracy: 0.7240 - val_loss: 10272.5107 - val_accuracy: 0.5666\n",
      "Epoch 11/100\n",
      "74/74 [==============================] - 8s 102ms/step - loss: 10138.1240 - accuracy: 0.7322 - val_loss: 10002.7754 - val_accuracy: 0.5341\n",
      "Epoch 12/100\n",
      "74/74 [==============================] - 8s 103ms/step - loss: 9881.9619 - accuracy: 0.7356 - val_loss: 9761.5439 - val_accuracy: 0.5956\n",
      "Epoch 13/100\n",
      "74/74 [==============================] - 8s 104ms/step - loss: 9652.2461 - accuracy: 0.7582 - val_loss: 9543.7520 - val_accuracy: 0.6263\n",
      "Epoch 14/100\n",
      "74/74 [==============================] - 8s 104ms/step - loss: 9443.6172 - accuracy: 0.7774 - val_loss: 9344.9668 - val_accuracy: 0.6877\n",
      "Epoch 15/100\n",
      "74/74 [==============================] - 8s 103ms/step - loss: 9252.0791 - accuracy: 0.8270 - val_loss: 9161.3203 - val_accuracy: 0.6570\n",
      "Epoch 16/100\n",
      "74/74 [==============================] - 8s 105ms/step - loss: 9076.2217 - accuracy: 0.8509 - val_loss: 8989.6074 - val_accuracy: 0.6570\n",
      "Epoch 17/100\n",
      "74/74 [==============================] - 8s 104ms/step - loss: 8908.8564 - accuracy: 0.8582 - val_loss: 8827.4727 - val_accuracy: 0.5956\n",
      "Epoch 18/100\n",
      "74/74 [==============================] - 8s 103ms/step - loss: 8750.3076 - accuracy: 0.8783 - val_loss: 8673.3164 - val_accuracy: 0.6570\n",
      "Epoch 19/100\n",
      "74/74 [==============================] - 8s 104ms/step - loss: 8599.0303 - accuracy: 0.9210 - val_loss: 8524.9199 - val_accuracy: 0.7509\n",
      "Epoch 20/100\n",
      "74/74 [==============================] - 8s 105ms/step - loss: 8452.6826 - accuracy: 0.9308 - val_loss: 8381.4287 - val_accuracy: 0.7509\n",
      "Epoch 21/100\n",
      "74/74 [==============================] - 8s 105ms/step - loss: 8311.5029 - accuracy: 0.9244 - val_loss: 8241.8037 - val_accuracy: 0.7816\n",
      "Epoch 22/100\n",
      "74/74 [==============================] - 8s 105ms/step - loss: 8173.7798 - accuracy: 0.9308 - val_loss: 8105.7148 - val_accuracy: 0.8123\n",
      "Epoch 23/100\n",
      "74/74 [==============================] - 8s 105ms/step - loss: 8039.3901 - accuracy: 0.9265 - val_loss: 7972.5117 - val_accuracy: 0.7509\n",
      "Epoch 24/100\n",
      "74/74 [==============================] - 8s 105ms/step - loss: 7907.8677 - accuracy: 0.9513 - val_loss: 7841.4214 - val_accuracy: 0.8123\n",
      "Epoch 25/100\n",
      "74/74 [==============================] - 8s 105ms/step - loss: 7777.8735 - accuracy: 0.9534 - val_loss: 7712.9121 - val_accuracy: 0.7509\n",
      "Epoch 26/100\n",
      "74/74 [==============================] - 8s 105ms/step - loss: 7650.2974 - accuracy: 0.9513 - val_loss: 7586.4683 - val_accuracy: 0.8123\n",
      "Epoch 27/100\n",
      "74/74 [==============================] - 8s 104ms/step - loss: 7524.2368 - accuracy: 0.9654 - val_loss: 7462.0308 - val_accuracy: 0.8123\n",
      "Epoch 28/100\n",
      "74/74 [==============================] - 8s 104ms/step - loss: 7401.2183 - accuracy: 0.9710 - val_loss: 7339.4438 - val_accuracy: 0.7509\n",
      "Epoch 29/100\n",
      "74/74 [==============================] - 8s 104ms/step - loss: 7279.9717 - accuracy: 0.9688 - val_loss: 7218.7007 - val_accuracy: 0.8123\n",
      "Epoch 30/100\n",
      "74/74 [==============================] - 8s 105ms/step - loss: 7159.8608 - accuracy: 0.9556 - val_loss: 7099.8955 - val_accuracy: 0.7816\n",
      "Epoch 31/100\n",
      "74/74 [==============================] - 8s 104ms/step - loss: 7042.1880 - accuracy: 0.9586 - val_loss: 6982.9189 - val_accuracy: 0.8123\n",
      "Epoch 32/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 6925.1606 - accuracy: 0.9705Restoring model weights from the end of the best epoch: 22.\n",
      "74/74 [==============================] - 8s 105ms/step - loss: 6925.1606 - accuracy: 0.9705 - val_loss: 6867.7188 - val_accuracy: 0.8123\n",
      "Epoch 32: early stopping\n"
     ]
    }
   ],
   "source": [
    "history_ChestX_err_norm = ChestX_err_norm.fit(train_all_generator, epochs=100, validation_data=valid_all_generator, callbacks= early_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "11177e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col_0    0    1    2\n",
      "row_0               \n",
      "0      229   30    1\n",
      "1       65  152   30\n",
      "2       42    7  176\n"
     ]
    }
   ],
   "source": [
    "y_pred_liste=[]\n",
    "y_true_liste=[]\n",
    "y_pred_argmax_liste=[]\n",
    "df_all_test = df_all_test.reset_index(drop=True)\n",
    "\n",
    "for i in range(len(df_all_test[\"path\"])):\n",
    "    #y_pred_norm_256 = df_all_test[\"outputs_128_to_256_norm\"][i]\n",
    "    y_erreur_norm_256 = df_all_test[\"erreur_128_to_256_norm\"][i]\n",
    "    #pn_256 = np.resize(1000-(-y_pred_norm_256+y_erreur_norm_256), (*(256,256),1))\n",
    "    pn_256 = np.resize(1000-(y_erreur_norm_256),(*(256,256),1))\n",
    "    pn_256 = (pn_256- np.min(pn_256)) / (np.max(pn_256) - np.min(pn_256))\n",
    "    pn_256 = np.reshape(pn_256,(*(256,256),1)).astype('float32') \n",
    "\n",
    "    \n",
    "    y= df_all_test[\"label\"][i]\n",
    "    y= np.resize(y, (1, 1))\n",
    "\n",
    "    batch_pn_256 = np.resize(pn_256, (1, *(256,256),1))\n",
    "    batch_y = y\n",
    "\n",
    "    y_pred = ChestX_err_norm.predict(batch_pn_256,verbose= 0)\n",
    "    y_pred_argmax = np.argmax(y_pred, axis=1)\n",
    "    y_pred_liste.extend(y_pred)\n",
    "    y_pred_argmax_liste.extend(y_pred_argmax)\n",
    "    y_true_liste.extend(y)\n",
    "    \n",
    "y_true_liste = np.reshape(y_true_liste, (732))\n",
    "y_pred_argmax_liste = np.reshape(y_pred_argmax_liste, (732))\n",
    "print(pd.crosstab(y_true_liste, y_pred_argmax_liste))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "941c471a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de lignes dans l'ensemble d'entraînement et de validation : 2927\n",
      "Nombre de lignes dans l'ensemble de test : 732\n",
      "Nombre de lignes dans l'ensemble d'entraînement : 2341\n",
      "Nombre de lignes dans l'ensemble de validation : 586\n"
     ]
    }
   ],
   "source": [
    "df_all_train, df_all_test = train_test_split(df_modif, test_size=0.2, random_state=168)\n",
    "train_all_df, val_all_df = train_test_split(df_all_train, test_size=0.2, random_state= 895)\n",
    "# Afficher le nombre de lignes de chaque ensemble de données\n",
    "print('Nombre de lignes dans l\\'ensemble d\\'entraînement et de validation :', len(df_all_train))\n",
    "print('Nombre de lignes dans l\\'ensemble de test :', len(df_all_test))\n",
    "print('Nombre de lignes dans l\\'ensemble d\\'entraînement :', len(train_all_df))\n",
    "print('Nombre de lignes dans l\\'ensemble de validation :', len(val_all_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ab25636b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataGenerator_256_err_pneumo(Sequence):\n",
    "    \n",
    "    def __init__(self, df, batch_size, input_size=(256,256), shuffle=True):\n",
    "        self.df = df\n",
    "        self.batch_size = batch_size\n",
    "        self.input_size = input_size\n",
    "        self.shuffle = shuffle\n",
    "        self.num_classes = 3 \n",
    "        self.on_epoch_end()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.df) / self.batch_size))\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        batch_df = self.df[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        batch_pn_256 = np.zeros((len(batch_df), *self.input_size, 1))\n",
    "        batch_y = np.zeros((len(batch_df), self.num_classes))\n",
    "\n",
    "        for i, row in enumerate(batch_df.itertuples()):\n",
    "            \n",
    "            #y_pred_pneumo_256 = self.df[\"outputs_128_to_256_pneumo\"][i]\n",
    "            y_erreur_pneumo_256 = self.df[\"erreur_128_to_256_pneumo\"][i]\n",
    "            #pn_256 = np.resize(1000-(-y_pred_pneumo_256+y_erreur_pneumo_256), (*self.input_size,1))\n",
    "            pn_256 = np.resize(1000-(y_erreur_pneumo_256),(*self.input_size,1))\n",
    "            pn_256 = self.augment_input(pn_256)\n",
    "            pn_256 = (pn_256- np.min(pn_256)) / (np.max(pn_256) - np.min(pn_256))\n",
    "            pn_256 = np.reshape(pn_256,(*(self.input_size),1)).astype('float32')  \n",
    "            \n",
    "            #rgb_img = np.zeros((pn_256.shape[0], pn_256.shape[1], 3), dtype=np.uint8)\n",
    "\n",
    "            # Replicate the grayscale channel to all three channels of the RGB image\n",
    "            #rgb_img[:,:,0] = pn_256\n",
    "            #rgb_img[:,:,1] = pn_256\n",
    "            #rgb_img[:,:,2] = pn_256\n",
    "\n",
    "            \n",
    "            # label encodé en one-hot\n",
    "            label = self.df[\"label\"][i]\n",
    "            y = np.zeros(self.num_classes)\n",
    "            y[label] = 1.0\n",
    "         \n",
    "\n",
    "            batch_pn_256[i] = pn_256\n",
    "            batch_y[i] = y\n",
    "        \n",
    "        return batch_pn_256, batch_y\n",
    "    \n",
    "    def augment_input(self,pn_256):\n",
    "    # Apply data augmentation to the input images x1 and x2\n",
    "        image_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "            rotation_range=20,  # rotation jusqu'à 30° \n",
    "            zoom_range=0.12,     # zoom juqu'à 10%\n",
    "            brightness_range=[0.85, 1.15], # luminosité impa\n",
    "            horizontal_flip=True,\n",
    "            fill_mode='nearest', # mode de completion de l'image modifié\n",
    "        )\n",
    "        seed = np.random.randint(0, 10000) # generate a random seed\n",
    "        pn_256 = image_generator.random_transform(pn_256, seed=seed)\n",
    "       \n",
    "        return  pn_256\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        # melange le dataframe à la fin de chaque epoch d'entrainement\n",
    "        if self.shuffle:\n",
    "            self.df = self.df.sample(frac=1)\n",
    "            \n",
    "class CustomDataGenerator_256_valid_err_pneumo(Sequence):\n",
    "    \n",
    "    def __init__(self, df, batch_size, input_size=(256,256), shuffle=False):\n",
    "        self.df = df\n",
    "        self.batch_size = batch_size\n",
    "        self.input_size = input_size\n",
    "        self.shuffle = shuffle\n",
    "        self.num_classes = 3 \n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.df) / self.batch_size))\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        batch_df = self.df[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        batch_pn_256 = np.zeros((len(batch_df), *self.input_size, 1))\n",
    "        batch_y = np.zeros((len(batch_df), self.num_classes))\n",
    "\n",
    "        for i, row in enumerate(batch_df.itertuples()):\n",
    "            \n",
    "            #y_pred_pneumo_256 = self.df[\"outputs_128_to_256_pneumo\"][i]\n",
    "            y_erreur_pneumo_256 = self.df[\"erreur_128_to_256_pneumo\"][i]\n",
    "            #pn_256 = np.resize(1000-(-y_pred_pneumo_256+y_erreur_pneumo_256), (*self.input_size,1))\n",
    "            pn_256 = np.resize(1000-(y_erreur_pneumo_256),(*self.input_size,1))                      \n",
    "            pn_256 = (pn_256- np.min(pn_256)) / (np.max(pn_256) - np.min(pn_256))\n",
    "            pn_256 = np.reshape(pn_256,(*(self.input_size),1)).astype('float32') \n",
    "            \n",
    "            #rgb_img = np.zeros((pn_256.shape[0], pn_256.shape[1], 3), dtype=np.uint8)\n",
    "\n",
    "            # Replicate the grayscale channel to all three channels of the RGB image\n",
    "            #rgb_img[:,:,0] = pn_256\n",
    "            #rgb_img[:,:,1] = pn_256\n",
    "            #rgb_img[:,:,2] = pn_256\n",
    "\n",
    "            \n",
    "            # label encodé en one-hot\n",
    "            label = self.df[\"label\"][i]\n",
    "            y = np.zeros(self.num_classes)\n",
    "            y[label] = 1.0\n",
    "         \n",
    "\n",
    "            batch_pn_256[i] = pn_256\n",
    "            batch_y[i] = y\n",
    "        \n",
    "        return batch_pn_256, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "55c5ad92",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all_df = train_all_df.reset_index(drop= True)\n",
    "val_all_df = val_all_df.reset_index(drop= True)\n",
    "\n",
    "train_all_generator=CustomDataGenerator_256_err_pneumo(train_all_df, batch_size=32)\n",
    "valid_all_generator=CustomDataGenerator_256_valid_err_pneumo(val_all_df, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "aa292b15",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_err_pneumo (InputLaye  [(None, 256, 256, 1)]    0         \n",
      " r)                                                              \n",
      "                                                                 \n",
      " err_pneumo_1 (Conv2D)       (None, 255, 255, 32)      160       \n",
      "                                                                 \n",
      " err_pneumo_2 (BatchNormaliz  (None, 255, 255, 32)     128       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " err_pneumo_3 (LeakyReLU)    (None, 255, 255, 32)      0         \n",
      "                                                                 \n",
      " err_pneumo_4 (MaxPooling2D)  (None, 127, 127, 32)     0         \n",
      "                                                                 \n",
      " err_pneumo_5 (Conv2D)       (None, 125, 125, 64)      18496     \n",
      "                                                                 \n",
      " err_pneumo_6 (BatchNormaliz  (None, 125, 125, 64)     256       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " err_pneumo_7 (LeakyReLU)    (None, 125, 125, 64)      0         \n",
      "                                                                 \n",
      " err_pneumo_8 (MaxPooling2D)  (None, 41, 41, 64)       0         \n",
      "                                                                 \n",
      " err_pneumo_9 (Conv2D)       (None, 39, 39, 256)       147712    \n",
      "                                                                 \n",
      " err_pneumo_10 (BatchNormali  (None, 39, 39, 256)      1024      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " err_pneumo_11 (LeakyReLU)   (None, 39, 39, 256)       0         \n",
      "                                                                 \n",
      " err_pneumo_12 (MaxPooling2D  (None, 19, 19, 256)      0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " err_pneumo_13 (Flatten)     (None, 92416)             0         \n",
      "                                                                 \n",
      " err_pneumo_14 (Dense)       (None, 256)               23658752  \n",
      "                                                                 \n",
      " err_pneumo_15 (LeakyReLU)   (None, 256)               0         \n",
      "                                                                 \n",
      " err_pneumo_16 (Dropout)     (None, 256)               0         \n",
      "                                                                 \n",
      " err_pneumo_17 (Dense)       (None, 128)               32896     \n",
      "                                                                 \n",
      " err_pneumo_18 (LeakyReLU)   (None, 128)               0         \n",
      "                                                                 \n",
      " err_pneumo_19 (Dropout)     (None, 128)               0         \n",
      "                                                                 \n",
      " err_pneumo_20 (Dense)       (None, 64)                8256      \n",
      "                                                                 \n",
      " err_pneumo_21 (LeakyReLU)   (None, 64)                0         \n",
      "                                                                 \n",
      " err_pneumo_22 (Dropout)     (None, 64)                0         \n",
      "                                                                 \n",
      " err_pneumo_23 (Dense)       (None, 32)                2080      \n",
      "                                                                 \n",
      " err_pneumo_24 (LeakyReLU)   (None, 32)                0         \n",
      "                                                                 \n",
      " err_pneumo_25 (BatchNormali  (None, 32)               128       \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " err_pneumo_26 (Dropout)     (None, 32)                0         \n",
      "                                                                 \n",
      " output_err_pneumo (Dense)   (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,869,987\n",
      "Trainable params: 23,869,219\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "layer_names_err_pneumo = ['input_err_pneumo'] + ['err_pneumo_{}'.format(i) for i in range(1, 27)] + ['output_err_pneumo']\n",
    "\n",
    "ChestX_err_pneumo= create_model(layer_names_err_pneumo)\n",
    "optimizer = Adamax(learning_rate=0.00001, beta_1=0.9)\n",
    "early_stop = EarlyStopping(monitor='val_accuracy', patience=10, verbose=1, restore_best_weights=True)\n",
    "ChestX_err_pneumo.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "ChestX_err_pneumo.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "616591db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "74/74 [==============================] - 9s 109ms/step - loss: 15956.6719 - accuracy: 0.4079 - val_loss: 15387.3926 - val_accuracy: 0.4710\n",
      "Epoch 2/100\n",
      "74/74 [==============================] - 8s 105ms/step - loss: 14913.9873 - accuracy: 0.4836 - val_loss: 14451.2197 - val_accuracy: 0.3413\n",
      "Epoch 3/100\n",
      "74/74 [==============================] - 8s 105ms/step - loss: 14038.3203 - accuracy: 0.4938 - val_loss: 13641.1055 - val_accuracy: 0.5939\n",
      "Epoch 4/100\n",
      "74/74 [==============================] - 8s 104ms/step - loss: 13283.9189 - accuracy: 0.4387 - val_loss: 12935.8281 - val_accuracy: 0.5614\n",
      "Epoch 5/100\n",
      "74/74 [==============================] - 8s 104ms/step - loss: 12627.6250 - accuracy: 0.4720 - val_loss: 12320.8750 - val_accuracy: 0.5922\n",
      "Epoch 6/100\n",
      "74/74 [==============================] - 8s 105ms/step - loss: 12050.4785 - accuracy: 0.4443 - val_loss: 11785.6104 - val_accuracy: 0.6894\n",
      "Epoch 7/100\n",
      "74/74 [==============================] - 8s 104ms/step - loss: 11549.6143 - accuracy: 0.4421 - val_loss: 11318.1826 - val_accuracy: 0.5631\n",
      "Epoch 8/100\n",
      "74/74 [==============================] - 8s 104ms/step - loss: 11114.0029 - accuracy: 0.4733 - val_loss: 10909.7871 - val_accuracy: 0.5939\n",
      "Epoch 9/100\n",
      "74/74 [==============================] - 8s 103ms/step - loss: 10730.1270 - accuracy: 0.4669 - val_loss: 10552.5576 - val_accuracy: 0.6246\n",
      "Epoch 10/100\n",
      "74/74 [==============================] - 8s 103ms/step - loss: 10393.9424 - accuracy: 0.4810 - val_loss: 10238.9365 - val_accuracy: 0.6246\n",
      "Epoch 11/100\n",
      "74/74 [==============================] - 8s 104ms/step - loss: 10099.8174 - accuracy: 0.4942 - val_loss: 9962.0879 - val_accuracy: 0.7184\n",
      "Epoch 12/100\n",
      "74/74 [==============================] - 8s 103ms/step - loss: 9839.0137 - accuracy: 0.5263 - val_loss: 9715.9072 - val_accuracy: 0.6553\n",
      "Epoch 13/100\n",
      "74/74 [==============================] - 8s 104ms/step - loss: 9605.0596 - accuracy: 0.5515 - val_loss: 9495.2354 - val_accuracy: 0.8123\n",
      "Epoch 14/100\n",
      "74/74 [==============================] - 8s 103ms/step - loss: 9394.8555 - accuracy: 0.5886 - val_loss: 9294.9941 - val_accuracy: 0.8123\n",
      "Epoch 15/100\n",
      "74/74 [==============================] - 8s 104ms/step - loss: 9203.3408 - accuracy: 0.6604 - val_loss: 9110.8574 - val_accuracy: 0.7509\n",
      "Epoch 16/100\n",
      "74/74 [==============================] - 8s 105ms/step - loss: 9025.4805 - accuracy: 0.7211 - val_loss: 8939.9385 - val_accuracy: 0.8123\n",
      "Epoch 17/100\n",
      "74/74 [==============================] - 8s 105ms/step - loss: 8859.3262 - accuracy: 0.7813 - val_loss: 8779.3564 - val_accuracy: 0.8430\n",
      "Epoch 18/100\n",
      "74/74 [==============================] - 8s 105ms/step - loss: 8703.5264 - accuracy: 0.8308 - val_loss: 8626.4551 - val_accuracy: 0.7799\n",
      "Epoch 19/100\n",
      "74/74 [==============================] - 8s 105ms/step - loss: 8552.9590 - accuracy: 0.8599 - val_loss: 8479.8428 - val_accuracy: 0.7184\n",
      "Epoch 20/100\n",
      "74/74 [==============================] - 8s 104ms/step - loss: 8409.8262 - accuracy: 0.8800 - val_loss: 8337.8096 - val_accuracy: 0.7491\n",
      "Epoch 21/100\n",
      "74/74 [==============================] - 8s 104ms/step - loss: 8268.6592 - accuracy: 0.8697 - val_loss: 8199.9990 - val_accuracy: 0.6536\n",
      "Epoch 22/100\n",
      "74/74 [==============================] - 8s 105ms/step - loss: 8132.0103 - accuracy: 0.9176 - val_loss: 8065.0059 - val_accuracy: 0.7491\n",
      "Epoch 23/100\n",
      "74/74 [==============================] - 8s 104ms/step - loss: 7999.5557 - accuracy: 0.9163 - val_loss: 7932.5913 - val_accuracy: 0.8430\n",
      "Epoch 24/100\n",
      "74/74 [==============================] - 8s 105ms/step - loss: 7868.2441 - accuracy: 0.8992 - val_loss: 7802.4668 - val_accuracy: 0.8447\n",
      "Epoch 25/100\n",
      "74/74 [==============================] - 8s 105ms/step - loss: 7738.7930 - accuracy: 0.9368 - val_loss: 7674.5469 - val_accuracy: 0.8123\n",
      "Epoch 26/100\n",
      "74/74 [==============================] - 8s 104ms/step - loss: 7612.1035 - accuracy: 0.9295 - val_loss: 7548.6313 - val_accuracy: 0.6860\n",
      "Epoch 27/100\n",
      "74/74 [==============================] - 8s 105ms/step - loss: 7486.3203 - accuracy: 0.9291 - val_loss: 7424.7617 - val_accuracy: 0.6877\n",
      "Epoch 28/100\n",
      "74/74 [==============================] - 8s 104ms/step - loss: 7363.8267 - accuracy: 0.9180 - val_loss: 7302.7192 - val_accuracy: 0.7833\n",
      "Epoch 29/100\n",
      "74/74 [==============================] - 8s 104ms/step - loss: 7243.2319 - accuracy: 0.9449 - val_loss: 7182.3491 - val_accuracy: 0.6843\n",
      "Epoch 30/100\n",
      "74/74 [==============================] - 8s 105ms/step - loss: 7123.0093 - accuracy: 0.9415 - val_loss: 7063.8989 - val_accuracy: 0.6536\n",
      "Epoch 31/100\n",
      "74/74 [==============================] - 8s 104ms/step - loss: 7005.7271 - accuracy: 0.9398 - val_loss: 6947.3091 - val_accuracy: 0.7150\n",
      "Epoch 32/100\n",
      "74/74 [==============================] - 8s 104ms/step - loss: 6890.3687 - accuracy: 0.9526 - val_loss: 6832.2754 - val_accuracy: 0.7184\n",
      "Epoch 33/100\n",
      "74/74 [==============================] - 8s 105ms/step - loss: 6775.2964 - accuracy: 0.9338 - val_loss: 6719.0874 - val_accuracy: 0.8123\n",
      "Epoch 34/100\n",
      "74/74 [==============================] - ETA: 0s - loss: 6663.0625 - accuracy: 0.9547Restoring model weights from the end of the best epoch: 24.\n",
      "74/74 [==============================] - 8s 105ms/step - loss: 6663.0625 - accuracy: 0.9547 - val_loss: 6607.5894 - val_accuracy: 0.7491\n",
      "Epoch 34: early stopping\n"
     ]
    }
   ],
   "source": [
    "history_ChestX_err_pneumo = ChestX_err_pneumo.fit(train_all_generator, epochs=100, validation_data=valid_all_generator, callbacks= early_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c1042fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col_0    0    1    2\n",
      "row_0               \n",
      "0      198   50   12\n",
      "1       41  197    9\n",
      "2        7   41  177\n"
     ]
    }
   ],
   "source": [
    "y_pred_liste=[]\n",
    "y_true_liste=[]\n",
    "y_pred_argmax_liste=[]\n",
    "df_all_test = df_all_test.reset_index(drop=True)\n",
    "\n",
    "for i in range(len(df_all_test[\"path\"])):\n",
    "    #y_pred_pneumo_256 = df_all_test[\"outputs_128_to_256_pneumo\"][i]\n",
    "    y_erreur_pneumo_256 = df_all_test[\"erreur_128_to_256_pneumo\"][i]\n",
    "    #pn_256 = np.resize(1000-(-y_pred_pneumo_256+y_erreur_pneumo_256), (*(256,256),1))\n",
    "    pn_256 = np.resize(1000-(y_erreur_pneumo_256),(*(256,256),1))\n",
    "    pn_256 = (pn_256- np.min(pn_256)) / (np.max(pn_256) - np.min(pn_256))\n",
    "    pn_256 = np.reshape(pn_256,(*(256,256),1)).astype('float32') \n",
    "\n",
    "    \n",
    "    y= df_all_test[\"label\"][i]\n",
    "    y= np.resize(y, (1, 1))\n",
    "\n",
    "    batch_pn_256 = np.resize(pn_256, (1, *(256,256),1))\n",
    "    batch_y = y\n",
    "\n",
    "    y_pred = ChestX_err_pneumo.predict(batch_pn_256,verbose= 0)\n",
    "    y_pred_argmax = np.argmax(y_pred, axis=1)\n",
    "    y_pred_liste.extend(y_pred)\n",
    "    y_pred_argmax_liste.extend(y_pred_argmax)\n",
    "    y_true_liste.extend(y)\n",
    "    \n",
    "y_true_liste = np.reshape(y_true_liste, (732))\n",
    "y_pred_argmax_liste = np.reshape(y_pred_argmax_liste, (732))\n",
    "print(pd.crosstab(y_true_liste, y_pred_argmax_liste))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "336eb66e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de lignes dans l'ensemble d'entraînement et de validation : 2927\n",
      "Nombre de lignes dans l'ensemble de test : 732\n",
      "Nombre de lignes dans l'ensemble d'entraînement : 2341\n",
      "Nombre de lignes dans l'ensemble de validation : 586\n"
     ]
    }
   ],
   "source": [
    "df_all_train, df_all_test = train_test_split(df_modif, test_size=0.2, random_state=168)\n",
    "train_all_df, val_all_df = train_test_split(df_all_train, test_size=0.2, random_state= 761)\n",
    "# Afficher le nombre de lignes de chaque ensemble de données\n",
    "print('Nombre de lignes dans l\\'ensemble d\\'entraînement et de validation :', len(df_all_train))\n",
    "print('Nombre de lignes dans l\\'ensemble de test :', len(df_all_test))\n",
    "print('Nombre de lignes dans l\\'ensemble d\\'entraînement :', len(train_all_df))\n",
    "print('Nombre de lignes dans l\\'ensemble de validation :', len(val_all_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "f8c4b01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataGenerator_all(Sequence):\n",
    "    \n",
    "    def __init__(self, df, batch_size, input_size=(256,256), shuffle=True):\n",
    "        self.df = df\n",
    "        self.batch_size = batch_size\n",
    "        self.input_size = input_size\n",
    "        self.shuffle = shuffle\n",
    "        self.num_classes = 3 \n",
    "        self.on_epoch_end()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.df) / self.batch_size))\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        batch_df = self.df[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        batch_y = np.zeros((len(batch_df), self.num_classes))\n",
    "        \n",
    "        \n",
    "        batch_pn_256 = np.zeros((len(batch_df), *self.input_size, 1))\n",
    "        batch_pp_256 = np.zeros((len(batch_df), *self.input_size, 1))\n",
    "        batch_pc_256 = np.zeros((len(batch_df), *self.input_size, 1))\n",
    "        \n",
    "        batch_en_256 = np.zeros((len(batch_df), *self.input_size, 1))\n",
    "        batch_ep_256 = np.zeros((len(batch_df), *self.input_size, 1))\n",
    "        batch_ec_256 = np.zeros((len(batch_df), *self.input_size, 1))\n",
    "        \n",
    "        batch_y = np.zeros((len(batch_df), self.num_classes))\n",
    "        \n",
    "        for i, row in enumerate(batch_df.itertuples()):\n",
    "            \n",
    "            \n",
    "            y_pred_norm_256 = self.df[\"outputs_128_to_256_norm\"][i]\n",
    "            y_pred_pneumo_256 = self.df[\"outputs_128_to_256_pneumo\"][i]\n",
    "            y_pred_covid_256 = self.df[\"outputs_128_to_256_covid\"][i]\n",
    "            \n",
    "            y_erreur_norm_256 = self.df[\"erreur_128_to_256_norm\"][i]\n",
    "            y_erreur_pneumo_256 = self.df[\"erreur_128_to_256_pneumo\"][i]\n",
    "            y_erreur_covid_256 = self.df[\"erreur_128_to_256_covid\"][i]\n",
    "            \n",
    "            y_pred_norm_256 = np.resize(1000-(y_pred_norm_256),(*self.input_size,1))\n",
    "            y_pred_pneumo_256 = np.resize(1000-(y_pred_pneumo_256),(*self.input_size,1))\n",
    "            y_pred_covid_256 = np.resize(1000-(y_pred_covid_256),(*self.input_size,1))\n",
    "            \n",
    "            y_erreur_norm_256 = np.resize(1000-(y_erreur_norm_256),(*self.input_size,1))\n",
    "            y_erreur_pneumo_256 = np.resize(1000-(y_erreur_pneumo_256),(*self.input_size,1))\n",
    "            y_erreur_covid_256 = np.resize(1000-(y_erreur_covid_256),(*self.input_size,1))\n",
    "                                   \n",
    "            pn_256, pp_256, pc_256,en_256, ep_256,ec_256 = self.augment_input(y_pred_norm_256, y_pred_pneumo_256, y_pred_covid_256,\n",
    "                                                                              y_erreur_norm_256, y_erreur_pneumo_256, y_erreur_covid_256)\n",
    "\n",
    "            \n",
    "            pn_256 = (pn_256- np.min(pn_256)) / (np.max(pn_256) - np.min(pn_256))\n",
    "            pn_256 = np.reshape(pn_256,(*self.input_size,1)).astype('float32') \n",
    "            \n",
    "            pp_256 = (pp_256- np.min(pp_256)) / (np.max(pp_256) - np.min(pp_256))\n",
    "            pp_256 = np.reshape(pp_256,(*self.input_size,1)).astype('float32') \n",
    "            \n",
    "            pc_256 = (pc_256- np.min(pc_256)) / (np.max(pc_256) - np.min(pc_256))\n",
    "            pc_256 = np.reshape(pc_256,(*self.input_size,1)).astype('float32') \n",
    "            \n",
    "            en_256 = (en_256- np.min(en_256)) / (np.max(en_256) - np.min(en_256))\n",
    "            en_256 = np.reshape(en_256,(*self.input_size,1)).astype('float32') \n",
    "            \n",
    "            ep_256 = (ep_256- np.min(ep_256)) / (np.max(ep_256) - np.min(ep_256))\n",
    "            ep_256 = np.reshape(ep_256,(*self.input_size,1)).astype('float32') \n",
    "            \n",
    "            ec_256 = (ec_256- np.min(ec_256)) / (np.max(ec_256) - np.min(ec_256))\n",
    "            ec_256 = np.reshape(ec_256,(*self.input_size,1)).astype('float32') \n",
    "            \n",
    "            \n",
    "            # label encodé en one-hot\n",
    "            label = self.df[\"label\"][i]\n",
    "            y = np.zeros(self.num_classes)\n",
    "            y[label] = 1.0\n",
    "\n",
    "            batch_pn_256[i] = pn_256\n",
    "            batch_pp_256[i] = pp_256\n",
    "            batch_pc_256[i] = pc_256\n",
    "\n",
    "            batch_en_256[i] = en_256\n",
    "            batch_ep_256[i] = ep_256\n",
    "            batch_ec_256[i] = ec_256\n",
    "            \n",
    "            batch_y[i] = y\n",
    "        \n",
    "        return [batch_pn_256,batch_pp_256,batch_pc_256,batch_en_256,batch_ep_256,batch_ec_256], batch_y\n",
    "    \n",
    "    def augment_input(self,pn_256, pp_256, pc_256,en_256, ep_256,ec_256):\n",
    "    # Apply data augmentation to the input images x1 and x2\n",
    "        image_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "            rotation_range=20,  # rotation jusqu'à 30° \n",
    "            zoom_range=0.15,     # zoom juqu'à 10%\n",
    "            brightness_range=[0.85, 1.15], # luminosité impa\n",
    "            horizontal_flip=True,\n",
    "            fill_mode='nearest', # mode de completion de l'image modifié\n",
    "        )\n",
    "        seed = np.random.randint(0, 10000)\n",
    "        pn_256 = image_generator.random_transform(pn_256, seed=seed)\n",
    "        pp_256 = image_generator.random_transform(pp_256, seed=seed)\n",
    "        pc_256 = image_generator.random_transform(pc_256, seed=seed)\n",
    "        en_256 = image_generator.random_transform(en_256, seed=seed)\n",
    "        ep_256 = image_generator.random_transform(ep_256, seed=seed)\n",
    "        ec_256 = image_generator.random_transform(ec_256, seed=seed)\n",
    "        return pn_256, pp_256, pc_256,en_256, ep_256,ec_256\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        # melange le dataframe à la fin de chaque epoch d'entrainement\n",
    "        if self.shuffle:\n",
    "            self.df = self.df.sample(frac=1)\n",
    "            \n",
    "class CustomDataGenerator_all_valid(Sequence):\n",
    "    \n",
    "    def __init__(self, df, batch_size, input_size=(256,256), shuffle=False):\n",
    "        self.df = df\n",
    "        self.batch_size = batch_size\n",
    "        self.input_size = input_size\n",
    "        self.num_classes = 3 \n",
    "        self.shuffle = shuffle\n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.df) / self.batch_size))\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        batch_df = self.df[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        batch_y = np.zeros((len(batch_df), self.num_classes))\n",
    "        \n",
    "        \n",
    "        batch_pn_256 = np.zeros((len(batch_df), *self.input_size, 1))\n",
    "        batch_pp_256 = np.zeros((len(batch_df), *self.input_size, 1))\n",
    "        batch_pc_256 = np.zeros((len(batch_df), *self.input_size, 1))\n",
    "        \n",
    "        batch_en_256 = np.zeros((len(batch_df), *self.input_size, 1))\n",
    "        batch_ep_256 = np.zeros((len(batch_df), *self.input_size, 1))\n",
    "        batch_ec_256 = np.zeros((len(batch_df), *self.input_size, 1))\n",
    "        \n",
    "        batch_y = np.zeros((len(batch_df), self.num_classes))\n",
    "        \n",
    "        for i, row in enumerate(batch_df.itertuples()):\n",
    "            \n",
    "            y_pred_norm_256 = self.df[\"outputs_128_to_256_norm\"][i]\n",
    "            y_pred_pneumo_256 = self.df[\"outputs_128_to_256_pneumo\"][i]\n",
    "            y_pred_covid_256 = self.df[\"outputs_128_to_256_covid\"][i]\n",
    "            \n",
    "            y_erreur_norm_256 = self.df[\"erreur_128_to_256_norm\"][i]\n",
    "            y_erreur_pneumo_256 = self.df[\"erreur_128_to_256_pneumo\"][i]\n",
    "            y_erreur_covid_256 = self.df[\"erreur_128_to_256_covid\"][i]\n",
    "            \n",
    "            pn_256 = np.resize(1000-(y_pred_norm_256),(*self.input_size,1))\n",
    "            pp_256 = np.resize(1000-(y_pred_pneumo_256),(*self.input_size,1))\n",
    "            pc_256 = np.resize(1000-(y_pred_covid_256),(*self.input_size,1))\n",
    "            \n",
    "            en_256 = np.resize(1000-(y_erreur_norm_256),(*self.input_size,1))\n",
    "            ep_256 = np.resize(1000-(y_erreur_pneumo_256),(*self.input_size,1))\n",
    "            ec_256 = np.resize(1000-(y_erreur_covid_256),(*self.input_size,1))\n",
    "                                   \n",
    "\n",
    "            pn_256 = (pn_256- np.min(pn_256)) / (np.max(pn_256) - np.min(pn_256))\n",
    "            pn_256 = np.reshape(pn_256,(*self.input_size,1)).astype('float32') \n",
    "            \n",
    "            pp_256 = (pp_256- np.min(pp_256)) / (np.max(pp_256) - np.min(pp_256))\n",
    "            pp_256 = np.reshape(pp_256,(*self.input_size,1)).astype('float32') \n",
    "            \n",
    "            pc_256 = (pc_256- np.min(pc_256)) / (np.max(pc_256) - np.min(pc_256))\n",
    "            pc_256 = np.reshape(pc_256,(*self.input_size,1)).astype('float32') \n",
    "            \n",
    "            en_256 = (en_256- np.min(en_256)) / (np.max(en_256) - np.min(en_256))\n",
    "            en_256 = np.reshape(en_256,(*self.input_size,1)).astype('float32') \n",
    "            \n",
    "            ep_256 = (ep_256- np.min(ep_256)) / (np.max(ep_256) - np.min(ep_256))\n",
    "            ep_256 = np.reshape(ep_256,(*self.input_size,1)).astype('float32') \n",
    "            \n",
    "            ec_256 = (ec_256- np.min(ec_256)) / (np.max(ec_256) - np.min(ec_256))\n",
    "            ec_256 = np.reshape(ec_256,(*self.input_size,1)).astype('float32') \n",
    "            \n",
    "            \n",
    "            # label encodé en one-hot\n",
    "            label = self.df[\"label\"][i]\n",
    "            y = np.zeros(self.num_classes)\n",
    "            y[label] = 1.0\n",
    "\n",
    "            batch_pn_256[i] = pn_256\n",
    "            batch_pp_256[i] = pp_256\n",
    "            batch_pc_256[i] = pc_256\n",
    "\n",
    "            batch_en_256[i] = en_256\n",
    "            batch_ep_256[i] = ep_256\n",
    "            batch_ec_256[i] = ec_256\n",
    "            \n",
    "            batch_y[i] = y\n",
    "        \n",
    "        return [batch_pn_256,batch_pp_256,batch_pc_256,batch_en_256,batch_ep_256,batch_ec_256], batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "e1b6c112",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_all_df = train_all_df.reset_index(drop= True)\n",
    "val_all_df = val_all_df.reset_index(drop= True)\n",
    "\n",
    "train_all_generator=CustomDataGenerator_all(train_all_df, batch_size=4)\n",
    "valid_all_generator=CustomDataGenerator_all_valid(val_all_df, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "74950d77",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_33\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_164 (InputLayer)         [(None, 256, 256, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " input_165 (InputLayer)         [(None, 256, 256, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " input_166 (InputLayer)         [(None, 256, 256, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " input_167 (InputLayer)         [(None, 256, 256, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " input_168 (InputLayer)         [(None, 256, 256, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " input_169 (InputLayer)         [(None, 256, 256, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " model_3 (Functional)           (None, 3)            23869987    ['input_164[0][0]']              \n",
      "                                                                                                  \n",
      " model_4 (Functional)           (None, 3)            23869987    ['input_165[0][0]']              \n",
      "                                                                                                  \n",
      " model_5 (Functional)           (None, 3)            23869987    ['input_166[0][0]']              \n",
      "                                                                                                  \n",
      " model_7 (Functional)           (None, 3)            23869987    ['input_167[0][0]']              \n",
      "                                                                                                  \n",
      " model_8 (Functional)           (None, 3)            23869987    ['input_168[0][0]']              \n",
      "                                                                                                  \n",
      " model_6 (Functional)           (None, 3)            23869987    ['input_169[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate_25 (Concatenate)   (None, 18)           0           ['model_3[13][0]',               \n",
      "                                                                  'model_4[13][0]',               \n",
      "                                                                  'model_5[13][0]',               \n",
      "                                                                  'model_7[14][0]',               \n",
      "                                                                  'model_8[14][0]',               \n",
      "                                                                  'model_6[13][0]']               \n",
      "                                                                                                  \n",
      " dense_85 (Dense)               (None, 128)          2432        ['concatenate_25[0][0]']         \n",
      "                                                                                                  \n",
      " leaky_re_lu_61 (LeakyReLU)     (None, 128)          0           ['dense_85[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_61 (Dropout)           (None, 128)          0           ['leaky_re_lu_61[0][0]']         \n",
      "                                                                                                  \n",
      " dense_86 (Dense)               (None, 64)           8256        ['dropout_61[0][0]']             \n",
      "                                                                                                  \n",
      " leaky_re_lu_62 (LeakyReLU)     (None, 64)           0           ['dense_86[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_62 (Dropout)           (None, 64)           0           ['leaky_re_lu_62[0][0]']         \n",
      "                                                                                                  \n",
      " dense_87 (Dense)               (None, 32)           2080        ['dropout_62[0][0]']             \n",
      "                                                                                                  \n",
      " leaky_re_lu_63 (LeakyReLU)     (None, 32)           0           ['dense_87[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_20 (BatchN  (None, 32)          128         ['leaky_re_lu_63[0][0]']         \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_63 (Dropout)           (None, 32)           0           ['batch_normalization_20[0][0]'] \n",
      "                                                                                                  \n",
      " dense_88 (Dense)               (None, 3)            99          ['dropout_63[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,232,917\n",
      "Trainable params: 12,931\n",
      "Non-trainable params: 143,219,986\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "predicted_input_norm_256 = Input(shape=(256, 256, 1))\n",
    "predicted_input_pneumo_256 = Input(shape=(256, 256, 1))\n",
    "predicted_input_covid_256 = Input(shape=(256, 256, 1))\n",
    "\n",
    "error_input_norm_256 = Input(shape=(256, 256, 1))\n",
    "error_input_pneumo_256 = Input(shape=(256, 256, 1))\n",
    "error_input_covid_256 = Input(shape=(256, 256, 1))\n",
    "\n",
    "net_err_norm = ChestX_err_norm(error_input_norm_256)\n",
    "net_err_pneumo = ChestX_err_pneumo(error_input_pneumo_256)\n",
    "net_err_covid = ChestX_err_covid(error_input_covid_256)\n",
    "\n",
    "net_norm = ChestX_norm(predicted_input_norm_256)\n",
    "net_pneumo = ChestX_pneumo(predicted_input_pneumo_256)\n",
    "net_covid = ChestX_covid(predicted_input_covid_256)\n",
    "\n",
    "for layer in ChestX_err_norm.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "for layer in ChestX_err_pneumo.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "for layer in ChestX_err_covid.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "for layer in ChestX_norm.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "for layer in ChestX_pneumo.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "for layer in ChestX_covid.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "from tensorflow.keras.layers import Concatenate\n",
    "concat= Concatenate(axis=1)([net_norm,net_pneumo,net_covid,net_err_norm,net_err_pneumo,net_err_covid])\n",
    "\n",
    "x = Dense(128, kernel_initializer='he_normal', kernel_regularizer=l2(0.1))(concat)\n",
    "x = LeakyReLU()(x)\n",
    "x = Dropout(0.25)(x)\n",
    "\n",
    "x = Dense(64, kernel_initializer='he_normal', kernel_regularizer=l2(0.1))(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = Dropout(0.3)(x)\n",
    "\n",
    "x = Dense(32, kernel_initializer='he_normal', kernel_regularizer=l2(0.1))(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.3)(x)\n",
    "\n",
    "outputs= Dense(3, activation='softmax')(x)\n",
    "\n",
    "ChestX_all= Model(inputs= [predicted_input_norm_256,predicted_input_pneumo_256,predicted_input_covid_256,error_input_norm_256,error_input_pneumo_256,error_input_covid_256], outputs= outputs)\n",
    "ChestX_all.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "e295a5e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"gradient_accumulate_model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_164 (InputLayer)         [(None, 256, 256, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " input_165 (InputLayer)         [(None, 256, 256, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " input_166 (InputLayer)         [(None, 256, 256, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " input_167 (InputLayer)         [(None, 256, 256, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " input_168 (InputLayer)         [(None, 256, 256, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " input_169 (InputLayer)         [(None, 256, 256, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " model_3 (Functional)           (None, 3)            23869987    ['input_164[0][0]']              \n",
      "                                                                                                  \n",
      " model_4 (Functional)           (None, 3)            23869987    ['input_165[0][0]']              \n",
      "                                                                                                  \n",
      " model_5 (Functional)           (None, 3)            23869987    ['input_166[0][0]']              \n",
      "                                                                                                  \n",
      " model_7 (Functional)           (None, 3)            23869987    ['input_167[0][0]']              \n",
      "                                                                                                  \n",
      " model_8 (Functional)           (None, 3)            23869987    ['input_168[0][0]']              \n",
      "                                                                                                  \n",
      " model_6 (Functional)           (None, 3)            23869987    ['input_169[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate_25 (Concatenate)   (None, 18)           0           ['model_3[13][0]',               \n",
      "                                                                  'model_4[13][0]',               \n",
      "                                                                  'model_5[13][0]',               \n",
      "                                                                  'model_7[14][0]',               \n",
      "                                                                  'model_8[14][0]',               \n",
      "                                                                  'model_6[13][0]']               \n",
      "                                                                                                  \n",
      " dense_85 (Dense)               (None, 128)          2432        ['concatenate_25[0][0]']         \n",
      "                                                                                                  \n",
      " leaky_re_lu_61 (LeakyReLU)     (None, 128)          0           ['dense_85[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_61 (Dropout)           (None, 128)          0           ['leaky_re_lu_61[0][0]']         \n",
      "                                                                                                  \n",
      " dense_86 (Dense)               (None, 64)           8256        ['dropout_61[0][0]']             \n",
      "                                                                                                  \n",
      " leaky_re_lu_62 (LeakyReLU)     (None, 64)           0           ['dense_86[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_62 (Dropout)           (None, 64)           0           ['leaky_re_lu_62[0][0]']         \n",
      "                                                                                                  \n",
      " dense_87 (Dense)               (None, 32)           2080        ['dropout_62[0][0]']             \n",
      "                                                                                                  \n",
      " leaky_re_lu_63 (LeakyReLU)     (None, 32)           0           ['dense_87[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_20 (BatchN  (None, 32)          128         ['leaky_re_lu_63[0][0]']         \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_63 (Dropout)           (None, 32)           0           ['batch_normalization_20[0][0]'] \n",
      "                                                                                                  \n",
      " dense_88 (Dense)               (None, 3)            99          ['dropout_63[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 143,245,849\n",
      "Trainable params: 12,931\n",
      "Non-trainable params: 143,232,918\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "optimizer = Adamax(learning_rate=0.001, beta_1=0.9)\n",
    "early_stop = EarlyStopping(monitor='val_accuracy', patience=10, verbose=1, restore_best_weights=True)\n",
    "\n",
    "\n",
    "\n",
    "# Compilation du modèle\n",
    "\n",
    "from gradient_accumulator import GradientAccumulateModel\n",
    "\n",
    "ChestX_all = GradientAccumulateModel(accum_steps=8, inputs=ChestX_all.input, outputs=ChestX_all.output)\n",
    "\n",
    "ChestX_all.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "ChestX_all.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "2eb7b27c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "586/586 [==============================] - 47s 79ms/step - loss: 49831.5820 - accuracy: 0.9680 - val_loss: 49830.1445 - val_accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "586/586 [==============================] - 46s 78ms/step - loss: 49828.9922 - accuracy: 0.9603 - val_loss: 49828.1172 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "586/586 [==============================] - 46s 79ms/step - loss: 49827.1367 - accuracy: 0.9821 - val_loss: 49826.5078 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "586/586 [==============================] - 46s 79ms/step - loss: 49826.1055 - accuracy: 0.9795 - val_loss: 49825.3633 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "586/586 [==============================] - 46s 78ms/step - loss: 49824.6289 - accuracy: 0.9880 - val_loss: 49824.4609 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history_ChestX_all = ChestX_all.fit(train_all_generator, epochs=5, validation_data=valid_all_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "23151f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col_0    0    1    2\n",
      "row_0               \n",
      "0      249    5    6\n",
      "1       38  201    8\n",
      "2        3    8  214\n"
     ]
    }
   ],
   "source": [
    "y_pred_liste=[]\n",
    "y_true_liste=[]\n",
    "y_pred_argmax_liste=[]\n",
    "df_all_test = df_all_test.reset_index(drop=True)\n",
    "\n",
    "for i in range(len(df_all_test[\"path\"])):\n",
    "    \n",
    "    y_pred_norm_256 = df_all_test[\"outputs_128_to_256_norm\"][i]\n",
    "    y_pred_pneumo_256 = df_all_test[\"outputs_128_to_256_pneumo\"][i]\n",
    "    y_pred_covid_256 = df_all_test[\"outputs_128_to_256_covid\"][i]\n",
    "\n",
    "    y_erreur_norm_256 = df_all_test[\"erreur_128_to_256_norm\"][i]\n",
    "    y_erreur_pneumo_256 = df_all_test[\"erreur_128_to_256_pneumo\"][i]\n",
    "    y_erreur_covid_256 = df_all_test[\"erreur_128_to_256_covid\"][i]\n",
    "\n",
    "    pn_256 = np.resize(1000-(y_pred_norm_256),(*(256,256),1))\n",
    "    pp_256 = np.resize(1000-(y_pred_pneumo_256),(*(256,256),1))\n",
    "    pc_256 = np.resize(1000-(y_pred_covid_256),(*(256,256),1))\n",
    "\n",
    "    en_256 = np.resize(1000-(y_erreur_norm_256),(*(256,256),1))\n",
    "    ep_256 = np.resize(1000-(y_erreur_pneumo_256),(*(256,256),1))\n",
    "    ec_256 = np.resize(1000-(y_erreur_covid_256),(*(256,256),1))\n",
    "\n",
    "\n",
    "    pn_256 = (pn_256- np.min(pn_256)) / (np.max(pn_256) - np.min(pn_256))\n",
    "    pn_256 = np.reshape(pn_256,(*(256,256),1)).astype('float32') \n",
    "\n",
    "    pp_256 = (pp_256- np.min(pp_256)) / (np.max(pp_256) - np.min(pp_256))\n",
    "    pp_256 = np.reshape(pp_256,(*(256,256),1)).astype('float32') \n",
    "\n",
    "    pc_256 = (pc_256- np.min(pc_256)) / (np.max(pc_256) - np.min(pc_256))\n",
    "    pc_256 = np.reshape(pc_256,(*(256,256),1)).astype('float32') \n",
    "\n",
    "    en_256 = (en_256- np.min(en_256)) / (np.max(en_256) - np.min(en_256))\n",
    "    en_256 = np.reshape(en_256,(*(256,256),1)).astype('float32') \n",
    "\n",
    "    ep_256 = (ep_256- np.min(ep_256)) / (np.max(ep_256) - np.min(ep_256))\n",
    "    ep_256 = np.reshape(ep_256,(*(256,256),1)).astype('float32') \n",
    "\n",
    "    ec_256 = (ec_256- np.min(ec_256)) / (np.max(ec_256) - np.min(ec_256))\n",
    "    ec_256 = np.reshape(ec_256,(*(256,256),1)).astype('float32')\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    batch_pn_256 = np.resize(pn_256, (1, *(256,256),1))\n",
    "    batch_pp_256 = np.resize(pp_256, (1, *(256,256),1))\n",
    "    batch_pc_256 = np.resize(pc_256, (1, *(256,256),1))\n",
    "    batch_en_256 = np.resize(en_256, (1, *(256,256),1))\n",
    "    batch_ep_256 = np.resize(ep_256, (1, *(256,256),1))\n",
    "    batch_ec_256 = np.resize(ec_256, (1, *(256,256),1))\n",
    "    \n",
    "    \n",
    "    y= df_all_test[\"label\"][i]\n",
    "    y= np.resize(y, (1, 1))\n",
    "    batch_y = y\n",
    "\n",
    "    y_pred = ChestX_all.predict([batch_pn_256,batch_pp_256,batch_pc_256,batch_en_256,batch_ep_256,batch_ec_256],verbose= 0)\n",
    "    y_pred_argmax = np.argmax(y_pred, axis=1)\n",
    "    y_pred_liste.extend(y_pred)\n",
    "    y_pred_argmax_liste.extend(y_pred_argmax)\n",
    "    y_true_liste.extend(y)\n",
    "    \n",
    "y_true_liste = np.reshape(y_true_liste, (732))\n",
    "y_pred_argmax_liste = np.reshape(y_pred_argmax_liste, (732))\n",
    "print(pd.crosstab(y_true_liste, y_pred_argmax_liste))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420509fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have 91% of accuracy which is not the best possible but is correct. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlowGPU",
   "language": "python",
   "name": "ml_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
